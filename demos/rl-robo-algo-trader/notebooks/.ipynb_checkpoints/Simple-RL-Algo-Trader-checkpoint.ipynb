{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48a3494f-c17c-4c84-9667-5f5a715dcf88",
   "metadata": {},
   "source": [
    "#### Simple DQN RL Stock Trader (Part1)\n",
    " - Simple stock trading RL-based algo trading agaent using S & P 500 data\n",
    " - Trading actions are buy, sel or hold\n",
    " - Trading window is daily\n",
    " - References are:\n",
    " - References:\n",
    "    - Yves J Hilpisch, \"Artificial Intelligence in Finance\", page 268 - 276, O'Reilly, 2021\n",
    "    - Mnih, V. et al., \"Human-level control through deep reinforcement learning\", Nature, 2015.\n",
    "    - Moody, J., Saffell, M., \"Learning to trade via direct reinforcement\", IEEE, 2001.\n",
    "    - Gymnasium API documentation: https://gymnasium.farama.org/\n",
    "    - PyTorch documentation: https://pytorch.org/docs/stable/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bade9d8a-2873-4eca-bcbb-a6640d7bb976",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "736f0b48-7394-4684-93ac-27a0e13a5270",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from collections import deque\n",
    "import ta\n",
    "import random\n",
    "import os\n",
    "from typing import Tuple, List, Any, Dict\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "from stable_baselines3 import DQN, PPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac4227-c6b5-4045-ba70-f3240048ab2e",
   "metadata": {},
   "source": [
    "#### Define global constants and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6bdb764-8d4c-4b76-a172-8f8afcaff454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure RL computations are reproducible by setting the seed\n",
    "SEED_VALUE = 100\n",
    "\n",
    "# S & P 500 data configurations\n",
    "DATA_PATH = \"../data\"\n",
    "S_P_RAW_DATA_PATH = f\"{DATA_PATH}/s_and_p_raw_data_with_features.csv\"\n",
    "S_P_SCALED_DATA_PATH = f\"{DATA_PATH}/s_and_p_scaled_data_with_features.csv\"\n",
    "ASSET_DATA_PATH = f\"{DATA_PATH}/aiif_eikon_eod_data.csv\"\n",
    "DATA_START_DATE=\"2010-01-01\"\n",
    "DATA_END_DATE=\"2020-01-01\"\n",
    "S_AND_P_YAHOO_TICKER = \"^GSPC\"\n",
    "DATA_BAR_TYPE = \"Close\"\n",
    "FEATURE_SMA_10 = \"SMA_10\"\n",
    "FEATURE_RSI = \"RSI\"\n",
    "FEATURE_MACD = \"MACD\"\n",
    "S_AND_P_DATA_COLUMNS = [DATA_BAR_TYPE, FEATURE_SMA_10, FEATURE_RSI, FEATURE_MACD]\n",
    "\n",
    "# Data partition configuration\n",
    "TEST_SPLIT_FACTOR=0.2\n",
    "\n",
    "# RL training configuration\n",
    "TRAINING_EPISODES_COUNT = 100\n",
    "TRAINING_AVERAGE_ROLLING_WINDOW = 50\n",
    "\n",
    "# RL validation/test configuration\n",
    "TEST_EPISODES_COUNT = 3\n",
    "\n",
    "# DQN agent hyper-parameter configurations\n",
    "REPLAY_EXPERIENCE_MEMORY_SIZE = 10_000\n",
    "LEARNING_RATE = 1e-3\n",
    "GAMMA = 0.95\n",
    "EPSILON = 1.0\n",
    "EPSILON_MIN = 0.01\n",
    "EPSILON_DECAY = 0.995\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Model persistence configuration\n",
    "MODEL_FOLDER = \"../model\"\n",
    "MODEL_RESULTS_FOLDER = \"../results\"\n",
    "os.makedirs(MODEL_FOLDER, exist_ok=True)\n",
    "os.makedirs(MODEL_RESULTS_FOLDER, exist_ok=True)\n",
    "MODEL_FILE_PATH = f\"{MODEL_FOLDER}/simple_rl_agent_v1.pt\"\n",
    "TRAIN_REWARDS_FILE_PATH = f\"{MODEL_RESULTS_FOLDER}/simple_rl_agent_v1_train_rewards.csv\"\n",
    "TRAIN_AVERAGE_REWARDS_FILE_PATH = f\"{MODEL_RESULTS_FOLDER}/simple_rl_agent_v1_train_average_rewards.csv\"\n",
    "TEST_REWARDS_FILE_PATH = f\"{MODEL_RESULTS_FOLDER}/simple_rl_agent_v1_test_rewards.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccbb3ee-92aa-49a3-836f-70dafd02f5a2",
   "metadata": {},
   "source": [
    "#### Define S & P 500 data provider component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42c6920f-bcb1-4903-9d88-37f1eb8193e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProvider:\n",
    "    \"\"\"\n",
    "    Component used to provide the S & P 500 dataset\n",
    "    :param s_and_p_raw_data_path: File path of raw data\n",
    "    :param s_and_p_scaled_data_path: File path of scaled data\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        s_and_p_raw_data_path: str = S_P_RAW_DATA_PATH,\n",
    "        s_and_p_scaled_data_path: str = S_P_SCALED_DATA_PATH\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        self._s_and_p_raw_data_path = s_and_p_raw_data_path\n",
    "        self._s_and_p_scaled_data_path = s_and_p_scaled_data_path\n",
    "        self._closing_price_raw_df = None\n",
    "        self._closing_price_raw = None\n",
    "        self._closing_price_scaled = None\n",
    "        self._closing_price_train = None\n",
    "        self._closing_price_test = None\n",
    "        self._data_scaler = None\n",
    "        self.features = None\n",
    "\n",
    "    def _featureEngineerData(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Feature engineer the S & P price data\n",
    "        :param df: Input dataframe\n",
    "        :return: Feature engineered data\n",
    "        \"\"\"\n",
    "        df[FEATURE_SMA_10] = ta.trend.sma_indicator(df[DATA_BAR_TYPE], window=10)\n",
    "        df[FEATURE_RSI] = ta.momentum.RSIIndicator(df[DATA_BAR_TYPE], window=14).rsi()\n",
    "        df[FEATURE_MACD] = ta.trend.macd_diff(df[DATA_BAR_TYPE])\n",
    "        df.dropna(inplace=True)\n",
    "        return df\n",
    "\n",
    "    def getData(self) -> Tuple[pd.DataFrame, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Gets the S & P closing price data\n",
    "        :return: Datasets\n",
    "        \"\"\"\n",
    "        if os.path.exists(self._s_and_p_raw_data_path):\n",
    "            print(f\"{self._s_and_p_raw_data_path} already exists in local file system (cache), ingesting the file locally\")\n",
    "            self._closing_price_raw_df = pd.read_csv(self._s_and_p_raw_data_path, index_col=None)\n",
    "        else:\n",
    "            print(f\"{self._s_and_p_raw_data_path} does not exists in local file system (cache), so ingesting the file from Yahoo Finance remote endpoint..\")\n",
    "            self._closing_price_raw_df = yf.download(S_AND_P_YAHOO_TICKER, start=DATA_START_DATE, end=DATA_END_DATE, multi_level_index=False)\n",
    "            self._closing_price_raw_df.to_csv(self._s_and_p_raw_data_path, index=False)             \n",
    "        if os.path.exists(self._s_and_p_scaled_data_path):\n",
    "            print(f\"{self._s_and_p_scaled_data_path} already exists in local file system (cache), ingesting the file locally\")\n",
    "            closing_price_scaled_df =  pd.read_csv(self._s_and_p_scaled_data_path, index_col=None)            \n",
    "            self._closing_price_with_features_scaled = closing_price_scaled_df[S_AND_P_DATA_COLUMNS].values\n",
    "        else:\n",
    "            print(f\"{self._s_and_p_scaled_data_path} does not exists in local file system (cache), so will recompute the data scaling..\")\n",
    "            close_prices_df = self._closing_price_raw_df[[DATA_BAR_TYPE]]\n",
    "            close_prices_with_features_df = self._featureEngineerData(close_prices_df)\n",
    "            \n",
    "            close_prices_with_features = close_prices_with_features_df.values\n",
    "            self._data_scaler = MinMaxScaler()\n",
    "            self._closing_price_with_features_scaled = self._data_scaler.fit_transform(close_prices_with_features)\n",
    "            closing_price_scaled_df = pd.DataFrame(self._closing_price_with_features_scaled, columns=[S_AND_P_DATA_COLUMNS])\n",
    "            closing_price_scaled_df.to_csv(self._s_and_p_scaled_data_path, index=False)\n",
    "        \n",
    "        self._partitionDataset()\n",
    "        \n",
    "        return  self._closing_price_raw_df, self._closing_price_with_features_scaled, self._closing_price_train, self._closing_price_test\n",
    "\n",
    "    def _partitionDataset(self, slit_fraction: float=TEST_SPLIT_FACTOR):\n",
    "        \"\"\"\n",
    "        Partitions data into training and test splits\n",
    "        :param slit_fraction: Split fraction\n",
    "        \"\"\"\n",
    "        prices = self._closing_price_with_features_scaled\n",
    "        split = int(len(prices) * 0.8)\n",
    "        self._closing_price_train, self._closing_price_test = prices[:split], prices[split:]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510563fd-f0f4-403b-9534-d8a2069ef961",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_provider = DataProvider()\n",
    "close_data_raw_df, close_data_scaled, close_data_train, close_data_test = data_provider.getData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c6eb8a-ab2a-4aac-ab4a-30feff9bf70c",
   "metadata": {},
   "source": [
    "#### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b646db95-9dab-40bb-a24a-aba47fc8b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Helpers:\n",
    "    \"\"\"\n",
    "    Helper utilities\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def appendTableRow(\n",
    "            df: pd.DataFrame,\n",
    "            row: pd.Series):\n",
    "        \"\"\"\n",
    "        :param df: Dataframe to append row to\n",
    "        :param row: Row to append\n",
    "        :return: New dataframe with appended row\n",
    "        \"\"\"\n",
    "        return pd.concat([\n",
    "            df,\n",
    "            pd.DataFrame([row], columns=row.index)]\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def createTable(\n",
    "        columns: List[str]\n",
    "        \n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Creates a new data table\n",
    "        :param columns: Columns\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame(\n",
    "            columns=columns\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def displayTable(\n",
    "        df: pd.DataFrame,\n",
    "        n_rows: int,\n",
    "        n_columns: int\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Displays sample rows of a data table\n",
    "        :param df: Data table\n",
    "        :param n_rows: Number of rows\n",
    "        \"\"\"\n",
    "        with pd.option_context(\"display.max_rows\", n_rows, \"display.max_columns\", n_columns,\n",
    "                       \"max_colwidth\", 100):\n",
    "            print(display(df[:n_rows]))\n",
    "\n",
    "    @staticmethod\n",
    "    def setSeeds(seed: int=SEED_VALUE):\n",
    "        \"\"\"\n",
    "        Sets the seed value for the computation to maintain reproducibility\n",
    "        :param seed: Seed value\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    @staticmethod\n",
    "    def getAssetData(data_path: str=ASSET_DATA_PATH) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Gets raw asset (Hilpisch) data\n",
    "        :param data_path: Data file path\n",
    "        :return: Data\n",
    "        \"\"\"\n",
    "        raw_data_df = pd.read_csv(data_path, index_col=0,\n",
    "                               parse_dates=True).dropna()\n",
    "        return raw_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f429279c-224e-467d-b079-b063db3afadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL.O</th>\n",
       "      <th>MSFT.O</th>\n",
       "      <th>INTC.O</th>\n",
       "      <th>AMZN.O</th>\n",
       "      <th>GS.N</th>\n",
       "      <th>SPY</th>\n",
       "      <th>.SPX</th>\n",
       "      <th>.VIX</th>\n",
       "      <th>EUR=</th>\n",
       "      <th>XAU=</th>\n",
       "      <th>GDX</th>\n",
       "      <th>GLD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>30.572827</td>\n",
       "      <td>30.950</td>\n",
       "      <td>20.88</td>\n",
       "      <td>133.90</td>\n",
       "      <td>173.08</td>\n",
       "      <td>113.33</td>\n",
       "      <td>1132.99</td>\n",
       "      <td>20.04</td>\n",
       "      <td>1.4411</td>\n",
       "      <td>1120.00</td>\n",
       "      <td>47.71</td>\n",
       "      <td>109.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>30.625684</td>\n",
       "      <td>30.960</td>\n",
       "      <td>20.87</td>\n",
       "      <td>134.69</td>\n",
       "      <td>176.14</td>\n",
       "      <td>113.63</td>\n",
       "      <td>1136.52</td>\n",
       "      <td>19.35</td>\n",
       "      <td>1.4368</td>\n",
       "      <td>1118.65</td>\n",
       "      <td>48.17</td>\n",
       "      <td>109.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>30.138541</td>\n",
       "      <td>30.770</td>\n",
       "      <td>20.80</td>\n",
       "      <td>132.25</td>\n",
       "      <td>174.26</td>\n",
       "      <td>113.71</td>\n",
       "      <td>1137.14</td>\n",
       "      <td>19.16</td>\n",
       "      <td>1.4412</td>\n",
       "      <td>1138.50</td>\n",
       "      <td>49.34</td>\n",
       "      <td>111.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>30.082827</td>\n",
       "      <td>30.452</td>\n",
       "      <td>20.60</td>\n",
       "      <td>130.00</td>\n",
       "      <td>177.67</td>\n",
       "      <td>114.19</td>\n",
       "      <td>1141.69</td>\n",
       "      <td>19.06</td>\n",
       "      <td>1.4318</td>\n",
       "      <td>1131.90</td>\n",
       "      <td>49.10</td>\n",
       "      <td>110.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>30.282827</td>\n",
       "      <td>30.660</td>\n",
       "      <td>20.83</td>\n",
       "      <td>133.52</td>\n",
       "      <td>174.31</td>\n",
       "      <td>114.57</td>\n",
       "      <td>1144.98</td>\n",
       "      <td>18.13</td>\n",
       "      <td>1.4412</td>\n",
       "      <td>1136.10</td>\n",
       "      <td>49.84</td>\n",
       "      <td>111.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AAPL.O  MSFT.O  INTC.O  AMZN.O    GS.N     SPY     .SPX   .VIX  \\\n",
       "Date                                                                            \n",
       "2010-01-04  30.572827  30.950   20.88  133.90  173.08  113.33  1132.99  20.04   \n",
       "2010-01-05  30.625684  30.960   20.87  134.69  176.14  113.63  1136.52  19.35   \n",
       "2010-01-06  30.138541  30.770   20.80  132.25  174.26  113.71  1137.14  19.16   \n",
       "2010-01-07  30.082827  30.452   20.60  130.00  177.67  114.19  1141.69  19.06   \n",
       "2010-01-08  30.282827  30.660   20.83  133.52  174.31  114.57  1144.98  18.13   \n",
       "\n",
       "              EUR=     XAU=    GDX     GLD  \n",
       "Date                                        \n",
       "2010-01-04  1.4411  1120.00  47.71  109.80  \n",
       "2010-01-05  1.4368  1118.65  48.17  109.70  \n",
       "2010-01-06  1.4412  1138.50  49.34  111.51  \n",
       "2010-01-07  1.4318  1131.90  49.10  110.82  \n",
       "2010-01-08  1.4412  1136.10  49.84  111.37  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Helpers.getAssetData()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd6b712-48c7-4b58-be0d-8ef1c7665b59",
   "metadata": {},
   "source": [
    "#### Define the custom trading environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "002a228c-ebc1-46d7-aaa8-0d8d4d64169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    RL asset trading environment    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        symbol: str, \n",
    "        features: List[str], \n",
    "        window: int, \n",
    "        lags: int,\n",
    "        leverage: int=1, \n",
    "        min_performance: float=0.85,\n",
    "        start: int=0, \n",
    "        end: int=None, \n",
    "        mu: float=None, \n",
    "        std: float=None):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        :param symbol: Asset symbol\n",
    "        :param features: Features\n",
    "        :param window: Data window\n",
    "        :param lag: Lag\n",
    "        :param leverage: Leverage\n",
    "        :param min_performance: Minimum performance\n",
    "        :param start: start\n",
    "        :param end: End\n",
    "        :param mu: Mean\n",
    "        :param std: Standard deviation\n",
    "        \"\"\"\n",
    "        self.symbol = symbol\n",
    "        self.features = features\n",
    "        self.n_features = len(features)\n",
    "        self.window = window\n",
    "        self.lags = lags\n",
    "        self.leverage = leverage\n",
    "        self.min_performance = min_performance\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.mu = mu\n",
    "        self.std = std\n",
    "        self.observation_space = gym.spaces.Box(low=-2, high=2, shape=(self.lags, self.n_features), dtype=np.float32)\n",
    "        self.action_space = gym.spaces.Discrete(2)\n",
    "        self.raw = Helpers.getAssetData()\n",
    "        self._prepare_data() \n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Step function\n",
    "        :param action: Action taken by the agent\n",
    "        :return: Observations, reward, done, truncated and infos\n",
    "        \"\"\"\n",
    "        self.correct = action == self.data_['d'].iloc[self.bar]\n",
    "        ret = self.data['r'].iloc[self.bar] * self.leverage\n",
    "        reward_1 = 1 if self.correct else 0\n",
    "        reward_2 = abs(ret) if self.correct else -abs(ret)\n",
    "        self.factor = 1 if self.correct else -1\n",
    "        self.treward += reward_1\n",
    "        self.bar += 1\n",
    "        self.accuracy = self.treward / (self.bar - self.lags)\n",
    "        self.performance *= math.exp(reward_2)\n",
    "        if self.bar >= len(self.data):\n",
    "            done = True\n",
    "        elif reward_1 == 1:\n",
    "            done = False\n",
    "        elif (self.performance < self.min_performance and\n",
    "              self.bar > self.lags + 5):\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "            \n",
    "        state = self.getState()\n",
    "        reward = reward_1 + reward_2 * 5\n",
    "        terminated = False\n",
    "        info = self._getInfos()\n",
    "        return state.values, reward, done, terminated, info      \n",
    "        \n",
    "\n",
    "    def reset(self, seed=SEED_VALUE, options=None) -> Tuple[np.ndarray, Dict]:\n",
    "        \"\"\"\n",
    "        Resets the RL environment\n",
    "        :param seed: Seed\n",
    "        :param options: Options\n",
    "        \"\"\"\n",
    "        self.treward = 0\n",
    "        self.accuracy = 0\n",
    "        self.performance = 1\n",
    "        self.bar = self.lags\n",
    "        state = self.data_[self.features].iloc[self.bar-\n",
    "                        self.lags:self.bar]        \n",
    "        return state.values, {}\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        \"\"\"\n",
    "        Prepares the asset data\n",
    "        \"\"\"\n",
    "        self.data = pd.DataFrame(self.raw[self.symbol])\n",
    "        self.data = self.data.iloc[self.start:]\n",
    "        self.data['r'] = np.log(self.data / self.data.shift(1))\n",
    "        self.data.dropna(inplace=True)\n",
    "        self.data['s'] = self.data[self.symbol].rolling(\n",
    "                                              self.window).mean() \n",
    "        self.data['m'] = self.data['r'].rolling(self.window).mean()\n",
    "        self.data['v'] = self.data['r'].rolling(self.window).std()\n",
    "        self.data.dropna(inplace=True)\n",
    "        if self.mu is None:\n",
    "            self.mu = self.data.mean()\n",
    "            self.std = self.data.std()\n",
    "        self.data_ = (self.data - self.mu) / self.std\n",
    "        self.data_['d'] = np.where(self.data['r'] > 0, 1, 0)\n",
    "        self.data_['d'] = self.data_['d'].astype(int)\n",
    "        if self.end is not None:\n",
    "            self.data = self.data.iloc[:self.end - self.start]\n",
    "            self.data_ = self.data_.iloc[:self.end - self.start]\n",
    "\n",
    "    def seed(self, seed):\n",
    "        \"\"\"\n",
    "        Seed to the random number generation\n",
    "        :param seed: Seed\n",
    "        \"\"\"\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    def getState(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gets the RL state\n",
    "        :return: State\n",
    "        \"\"\"\n",
    "        return self.data_[self.features].iloc[self.bar -\n",
    "                                self.lags:self.bar]\n",
    "\n",
    "    def _getObservations(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Gets the RL environment onservations\n",
    "        :param observations: Observations\n",
    "        \"\"\"\n",
    "        return np.array([self.features[self.current_step]], dtype=np.float32)\n",
    "\n",
    "    def _getInfos(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Gets the RL infos\n",
    "        :return: RL infos\n",
    "        \"\"\"\n",
    "        info = {\n",
    "            \"correct\": self.correct,\n",
    "            \"factor\": self.factor,\n",
    "            \"accuracy\": self.accuracy,\n",
    "            \"bar\": self.bar,\n",
    "            \"performance\": self.performance,\n",
    "    \n",
    "        }\n",
    "        return info\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25b57eb-bd1c-4ea0-87bf-30bd76847b04",
   "metadata": {},
   "source": [
    "#### Let us use a random agent to trade the asset portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cc089fa-c8a8-4588-8119-e282e851f85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adeid\\AppData\\Local\\Temp\\ipykernel_17948\\3541914538.py:14: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  return pd.concat([\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>state</th>\n",
       "      <th>next_state</th>\n",
       "      <th>reward</th>\n",
       "      <th>done</th>\n",
       "      <th>truncated</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[[1.772060547322853, -1.0213535688271376, 1.8772881381524675, -0.39389674115072043, 0.0350896226...</td>\n",
       "      <td>[[1.5973158387206814, -2.4431843864073235, 1.8535858323718988, -1.0211676868251565, 0.6954352920...</td>\n",
       "      <td>-0.027283</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'correct': False, 'factor': -1, 'accuracy': 0.0, 'bar': 6, 'performance': 0.9945583038869258}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[1.5973158387206814, -2.4431843864073235, 1.8535858323718988, -1.0211676868251565, 0.6954352920...</td>\n",
       "      <td>[[1.5875585199662465, -0.12078195478970356, 1.825001029145894, -1.2423312747278847, 0.5999729990...</td>\n",
       "      <td>-0.019936</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'correct': False, 'factor': -1, 'accuracy': 0.0, 'bar': 7, 'performance': 0.9906007067137809}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[[1.5875585199662465, -0.12078195478970356, 1.825001029145894, -1.2423312747278847, 0.5999729990...</td>\n",
       "      <td>[[1.6292488819170177, 0.6083036347667816, 1.8089331739163708, -0.6733641480088325, 0.61232777133...</td>\n",
       "      <td>1.019658</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'correct': True, 'factor': 1, 'accuracy': 0.3333333333333333, 'bar': 8, 'performance': 0.994502...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[[1.6292488819170177, 0.6083036347667816, 1.8089331739163708, -0.6733641480088325, 0.61232777133...</td>\n",
       "      <td>[[1.6407802586268063, 0.18066536999252064, 1.7856747315399315, -0.9974713645896238, 0.3693072136...</td>\n",
       "      <td>1.035940</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'correct': True, 'factor': 1, 'accuracy': 0.5, 'bar': 9, 'performance': 1.0016772547977972}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[[1.6407802586268063, 0.18066536999252064, 1.7856747315399315, -0.9974713645896238, 0.3693072136...</td>\n",
       "      <td>[[1.5724790273457543, -0.9501925693675054, 1.746614751976445, -1.714318473729268, 0.003519664432...</td>\n",
       "      <td>1.023391</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'correct': True, 'factor': 1, 'accuracy': 0.6, 'bar': 10, 'performance': 1.0063741976315772}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  action  \\\n",
       "0      1   \n",
       "1      1   \n",
       "2      0   \n",
       "3      0   \n",
       "4      1   \n",
       "\n",
       "                                                                                                 state  \\\n",
       "0  [[1.772060547322853, -1.0213535688271376, 1.8772881381524675, -0.39389674115072043, 0.0350896226...   \n",
       "1  [[1.5973158387206814, -2.4431843864073235, 1.8535858323718988, -1.0211676868251565, 0.6954352920...   \n",
       "2  [[1.5875585199662465, -0.12078195478970356, 1.825001029145894, -1.2423312747278847, 0.5999729990...   \n",
       "3  [[1.6292488819170177, 0.6083036347667816, 1.8089331739163708, -0.6733641480088325, 0.61232777133...   \n",
       "4  [[1.6407802586268063, 0.18066536999252064, 1.7856747315399315, -0.9974713645896238, 0.3693072136...   \n",
       "\n",
       "                                                                                            next_state  \\\n",
       "0  [[1.5973158387206814, -2.4431843864073235, 1.8535858323718988, -1.0211676868251565, 0.6954352920...   \n",
       "1  [[1.5875585199662465, -0.12078195478970356, 1.825001029145894, -1.2423312747278847, 0.5999729990...   \n",
       "2  [[1.6292488819170177, 0.6083036347667816, 1.8089331739163708, -0.6733641480088325, 0.61232777133...   \n",
       "3  [[1.6407802586268063, 0.18066536999252064, 1.7856747315399315, -0.9974713645896238, 0.3693072136...   \n",
       "4  [[1.5724790273457543, -0.9501925693675054, 1.746614751976445, -1.714318473729268, 0.003519664432...   \n",
       "\n",
       "     reward   done truncated  \\\n",
       "0 -0.027283  False     False   \n",
       "1 -0.019936  False     False   \n",
       "2  1.019658  False     False   \n",
       "3  1.035940  False     False   \n",
       "4  1.023391  False     False   \n",
       "\n",
       "                                                                                                  info  \n",
       "0       {'correct': False, 'factor': -1, 'accuracy': 0.0, 'bar': 6, 'performance': 0.9945583038869258}  \n",
       "1       {'correct': False, 'factor': -1, 'accuracy': 0.0, 'bar': 7, 'performance': 0.9906007067137809}  \n",
       "2  {'correct': True, 'factor': 1, 'accuracy': 0.3333333333333333, 'bar': 8, 'performance': 0.994502...  \n",
       "3         {'correct': True, 'factor': 1, 'accuracy': 0.5, 'bar': 9, 'performance': 1.0016772547977972}  \n",
       "4        {'correct': True, 'factor': 1, 'accuracy': 0.6, 'bar': 10, 'performance': 1.0063741976315772}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "\n",
      "env.getState():\n",
      "                EUR=         r         s         m         v\n",
      "Date                                                        \n",
      "2010-01-26  1.572479 -0.950193  1.746615 -1.714318  0.003520\n",
      "2010-01-27  1.522805 -0.689571  1.704270 -1.868586 -0.011352\n",
      "2010-01-28  1.474019 -0.679698  1.655623 -2.158711 -0.122578\n",
      "2010-01-29  1.385316 -1.257311  1.598808 -2.541134 -0.144125\n",
      "2010-02-01  1.442973  0.847393  1.558417 -1.792761  0.118917\n"
     ]
    }
   ],
   "source": [
    "def testRLWithRandomAgent():\n",
    "    \"\"\"\n",
    "    Test the environment with a random RL agent\n",
    "    \"\"\"\n",
    "    columns = [\"action\", \"state\", \"next_state\", \"reward\", \"done\", \"truncated\", \"info\"]\n",
    "    results_df = Helpers.createTable(columns=columns)\n",
    "    \n",
    "    n_episodes = 5\n",
    "    symbol = \"EUR=\"\n",
    "    features = [symbol, \"r\", \"s\", \"m\", \"v\"]\n",
    "    window = 10\n",
    "    lag = 5\n",
    "    env = TradingEnv(symbol,features, window, lag )\n",
    "    assert env != None, \"Incorrect env constructed!!\"\n",
    "    state, info = env.reset()    \n",
    "    for i in range(n_episodes):\n",
    "        action = env.action_space.sample()\n",
    "        next_state, reward, done, truncated, info = env.step(action)\n",
    "        new_row = pd.Series(\n",
    "            {\n",
    "                \"action\": action,\n",
    "                \"state\": state,\n",
    "                \"next_state\": next_state,\n",
    "                \"reward\": reward,\n",
    "                \"done\": done,\n",
    "                \"truncated\": truncated,\n",
    "                \"info\": info,\n",
    "            })\n",
    "        results_df = Helpers.appendTableRow(results_df, new_row)\n",
    "        state = next_state\n",
    "    Helpers.displayTable(results_df, n_rows=10, n_columns=len(columns))\n",
    "    print(f\"\\n\\nenv.getState():\\n{env.getState()}\")\n",
    "    \n",
    "\n",
    "testRLWithRandomAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c86bec-2f76-4174-9bb3-01530c717f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af414239-4c3a-4c02-8b4a-48034f6ffe39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211ffa68c33f4f4c889a3030fbdb3aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 182      |\n",
      "|    ep_rew_mean     | 84.5     |\n",
      "| time/              |          |\n",
      "|    fps             | 288      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 651          |\n",
      "|    ep_rew_mean          | 325          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 237          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077628917 |\n",
      "|    clip_fraction        | 0.0385       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.687       |\n",
      "|    explained_variance   | -0.0141      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.1          |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00576     |\n",
      "|    value_loss           | 33.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 656         |\n",
      "|    ep_rew_mean          | 326         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 224         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006320974 |\n",
      "|    clip_fraction        | 0.031       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.683      |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.08        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00527    |\n",
      "|    value_loss           | 21.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 887         |\n",
      "|    ep_rew_mean          | 440         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 217         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006433448 |\n",
      "|    clip_fraction        | 0.0556      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.35        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    value_loss           | 12          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 852         |\n",
      "|    ep_rew_mean          | 420         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 214         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009591317 |\n",
      "|    clip_fraction        | 0.0551      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.678      |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.16        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    value_loss           | 7.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 990         |\n",
      "|    ep_rew_mean          | 490         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 211         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009971818 |\n",
      "|    clip_fraction        | 0.0495      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.665      |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.44        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 990         |\n",
      "|    ep_rew_mean          | 490         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 210         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004939909 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.673      |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.99        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.11e+03     |\n",
      "|    ep_rew_mean          | 550          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 208          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 78           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054470906 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.667       |\n",
      "|    explained_variance   | 0.816        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.89         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    value_loss           | 7.64         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | 600         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 207         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006951106 |\n",
      "|    clip_fraction        | 0.0444      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.648      |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.57        |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    value_loss           | 6.28        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.29e+03     |\n",
      "|    ep_rew_mean          | 646          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 99           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047559766 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.651       |\n",
      "|    explained_variance   | 0.836        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.2          |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    value_loss           | 6.68         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.37e+03     |\n",
      "|    ep_rew_mean          | 685          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 109          |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068470733 |\n",
      "|    clip_fraction        | 0.049        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.63        |\n",
      "|    explained_variance   | 0.817        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.8          |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00624     |\n",
      "|    value_loss           | 6.44         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | 719         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 205         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005049535 |\n",
      "|    clip_fraction        | 0.0225      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.634      |\n",
      "|    explained_variance   | 0.789       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.01        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    value_loss           | 6.4         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31e+03    |\n",
      "|    ep_rew_mean          | 654         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 205         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003958177 |\n",
      "|    clip_fraction        | 0.0221      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.615      |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.55        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    value_loss           | 7.29        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.34e+03     |\n",
      "|    ep_rew_mean          | 670          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 139          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062172166 |\n",
      "|    clip_fraction        | 0.0732       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.591       |\n",
      "|    explained_variance   | 0.149        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.07         |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00515     |\n",
      "|    value_loss           | 18.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.39e+03     |\n",
      "|    ep_rew_mean          | 699          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 204          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 149          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047471533 |\n",
      "|    clip_fraction        | 0.0595       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.588       |\n",
      "|    explained_variance   | 0.253        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.25         |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00469     |\n",
      "|    value_loss           | 10           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.39e+03     |\n",
      "|    ep_rew_mean          | 699          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 204          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 160          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062052705 |\n",
      "|    clip_fraction        | 0.0627       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.564       |\n",
      "|    explained_variance   | 0.315        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.98         |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00878     |\n",
      "|    value_loss           | 14.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.44e+03    |\n",
      "|    ep_rew_mean          | 726         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 204         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 170         |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004099169 |\n",
      "|    clip_fraction        | 0.0294      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.557      |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.44        |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    value_loss           | 3.47        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | 750         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 204         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006633576 |\n",
      "|    clip_fraction        | 0.0551      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.541      |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.1         |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    value_loss           | 9.45        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 773          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 203          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 190          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030155722 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.532       |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.65         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    value_loss           | 7.76         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 773          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 203          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 201          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035376158 |\n",
      "|    clip_fraction        | 0.0449       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.658        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.02         |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    value_loss           | 8.67         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | 793          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 203          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 211          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054422366 |\n",
      "|    clip_fraction        | 0.0617       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.489       |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.831        |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00596     |\n",
      "|    value_loss           | 10.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | 811          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 203          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 221          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029320666 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.78         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.3          |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    value_loss           | 9.46         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.62e+03     |\n",
      "|    ep_rew_mean          | 828          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 203          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 231          |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034099068 |\n",
      "|    clip_fraction        | 0.0373       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.477       |\n",
      "|    explained_variance   | 0.791        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.1          |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    value_loss           | 8.41         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.62e+03     |\n",
      "|    ep_rew_mean          | 828          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 203          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 241          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027184119 |\n",
      "|    clip_fraction        | 0.035        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.465       |\n",
      "|    explained_variance   | 0.771        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.32         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    value_loss           | 8.9          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.65e+03    |\n",
      "|    ep_rew_mean          | 844         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 202         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 252         |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005669369 |\n",
      "|    clip_fraction        | 0.0651      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.449      |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    value_loss           | 2.37        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.68e+03     |\n",
      "|    ep_rew_mean          | 860          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 202          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 262          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025674978 |\n",
      "|    clip_fraction        | 0.0408       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.429       |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    value_loss           | 8.59         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+03    |\n",
      "|    ep_rew_mean          | 876         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 202         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004731115 |\n",
      "|    clip_fraction        | 0.0403      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.412      |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.04        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    value_loss           | 8.97        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.73e+03     |\n",
      "|    ep_rew_mean          | 889          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 202          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 283          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029382382 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.426       |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.35         |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    value_loss           | 8.66         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.73e+03     |\n",
      "|    ep_rew_mean          | 889          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 202          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 293          |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021472855 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.413       |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.84         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    value_loss           | 9.4          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.77e+03     |\n",
      "|    ep_rew_mean          | 914          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 202          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 313          |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015148886 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.414       |\n",
      "|    explained_variance   | 0.505        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 14.5         |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -3.47e-05    |\n",
      "|    value_loss           | 9.26         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | 926          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 202          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 323          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018867423 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.413       |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.37         |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.000703    |\n",
      "|    value_loss           | 8.46         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.81e+03     |\n",
      "|    ep_rew_mean          | 937          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 334          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027722353 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.426       |\n",
      "|    explained_variance   | 0.718        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.93         |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    value_loss           | 8.82         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.83e+03    |\n",
      "|    ep_rew_mean          | 947         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 344         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002237224 |\n",
      "|    clip_fraction        | 0.0315      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.422      |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.09        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00397    |\n",
      "|    value_loss           | 9.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.83e+03    |\n",
      "|    ep_rew_mean          | 947         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 355         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002993404 |\n",
      "|    clip_fraction        | 0.0376      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.425      |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.55        |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    value_loss           | 8.19        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.85e+03    |\n",
      "|    ep_rew_mean          | 957         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 365         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005555821 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.384      |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.3         |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    value_loss           | 2.43        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.88e+03    |\n",
      "|    ep_rew_mean          | 976         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 385         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002564813 |\n",
      "|    clip_fraction        | 0.0262      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.412      |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.86        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00173    |\n",
      "|    value_loss           | 8.49        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.9e+03     |\n",
      "|    ep_rew_mean          | 985         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 395         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002163074 |\n",
      "|    clip_fraction        | 0.0266      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.402      |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.86        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00288    |\n",
      "|    value_loss           | 8.74        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.9e+03     |\n",
      "|    ep_rew_mean          | 985         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 406         |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001812493 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.39       |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.11        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.000933   |\n",
      "|    value_loss           | 8.95        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.91e+03     |\n",
      "|    ep_rew_mean          | 992          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 416          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044724075 |\n",
      "|    clip_fraction        | 0.0488       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.376       |\n",
      "|    explained_variance   | 0.519        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.83         |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.0056      |\n",
      "|    value_loss           | 3.05         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.92e+03     |\n",
      "|    ep_rew_mean          | 1e+03        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 426          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027713357 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.372       |\n",
      "|    explained_variance   | 0.689        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.09         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    value_loss           | 8.35         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.94e+03    |\n",
      "|    ep_rew_mean          | 1.01e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 436         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002387673 |\n",
      "|    clip_fraction        | 0.0504      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.372      |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.6         |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00323    |\n",
      "|    value_loss           | 7.04        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.95e+03    |\n",
      "|    ep_rew_mean          | 1.02e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 446         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001631777 |\n",
      "|    clip_fraction        | 0.0255      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.363      |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.47        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    value_loss           | 8.85        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.96e+03     |\n",
      "|    ep_rew_mean          | 1.02e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 456          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025829664 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.361       |\n",
      "|    explained_variance   | 0.789        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.88         |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.000695    |\n",
      "|    value_loss           | 8.07         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.96e+03    |\n",
      "|    ep_rew_mean          | 1.02e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 466         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003225098 |\n",
      "|    clip_fraction        | 0.031       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.362      |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.74        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    value_loss           | 8.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.97e+03    |\n",
      "|    ep_rew_mean          | 1.03e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 477         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005940904 |\n",
      "|    clip_fraction        | 0.0676      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.33       |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.37        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    value_loss           | 2.29        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.98e+03     |\n",
      "|    ep_rew_mean          | 1.04e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 487          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022537091 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.33        |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.06         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.000956    |\n",
      "|    value_loss           | 8.44         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.99e+03     |\n",
      "|    ep_rew_mean          | 1.04e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 497          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016886691 |\n",
      "|    clip_fraction        | 0.024        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.34        |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.1          |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    value_loss           | 7.86         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+03       |\n",
      "|    ep_rew_mean          | 1.05e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 508         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004024023 |\n",
      "|    clip_fraction        | 0.0365      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.341      |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    value_loss           | 7.1         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | 1.05e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 518          |\n",
      "|    total_timesteps      | 104448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021243487 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.332       |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.64         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00149     |\n",
      "|    value_loss           | 7.69         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | 1.05e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 528          |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064064553 |\n",
      "|    clip_fraction        | 0.0548       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.314       |\n",
      "|    explained_variance   | 0.459        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.14         |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    value_loss           | 2.4          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.02e+03     |\n",
      "|    ep_rew_mean          | 1.06e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 538          |\n",
      "|    total_timesteps      | 108544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037082066 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.3         |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.55         |\n",
      "|    n_updates            | 520          |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    value_loss           | 8.12         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.03e+03     |\n",
      "|    ep_rew_mean          | 1.06e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 548          |\n",
      "|    total_timesteps      | 110592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031810233 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.281       |\n",
      "|    explained_variance   | 0.801        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6            |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    value_loss           | 6.61         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.04e+03     |\n",
      "|    ep_rew_mean          | 1.07e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 559          |\n",
      "|    total_timesteps      | 112640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012094444 |\n",
      "|    clip_fraction        | 0.0082       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.292       |\n",
      "|    explained_variance   | 0.786        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.981        |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    value_loss           | 7.85         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.05e+03     |\n",
      "|    ep_rew_mean          | 1.07e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 579          |\n",
      "|    total_timesteps      | 116736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014756464 |\n",
      "|    clip_fraction        | 0.0223       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.3         |\n",
      "|    explained_variance   | 0.758        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.61         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00128     |\n",
      "|    value_loss           | 7.87         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.05e+03     |\n",
      "|    ep_rew_mean          | 1.08e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 589          |\n",
      "|    total_timesteps      | 118784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075941496 |\n",
      "|    clip_fraction        | 0.0638       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.286       |\n",
      "|    explained_variance   | 0.335        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.733        |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.00711     |\n",
      "|    value_loss           | 1.99         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.06e+03     |\n",
      "|    ep_rew_mean          | 1.08e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 599          |\n",
      "|    total_timesteps      | 120832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029561373 |\n",
      "|    clip_fraction        | 0.0273       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.294       |\n",
      "|    explained_variance   | 0.541        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.33         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.0007      |\n",
      "|    value_loss           | 7.5          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.07e+03     |\n",
      "|    ep_rew_mean          | 1.09e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 610          |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012977622 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.309       |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49         |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.00109     |\n",
      "|    value_loss           | 7.51         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.08e+03     |\n",
      "|    ep_rew_mean          | 1.09e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 620          |\n",
      "|    total_timesteps      | 124928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015917943 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.309       |\n",
      "|    explained_variance   | 0.765        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.81         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    value_loss           | 7.25         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.08e+03     |\n",
      "|    ep_rew_mean          | 1.09e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 630          |\n",
      "|    total_timesteps      | 126976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016891157 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.314       |\n",
      "|    explained_variance   | 0.767        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49         |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    value_loss           | 7.63         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.08e+03    |\n",
      "|    ep_rew_mean          | 1.1e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 640         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005858806 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.303      |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.806       |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.00685    |\n",
      "|    value_loss           | 2.48        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.09e+03    |\n",
      "|    ep_rew_mean          | 1.1e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 650         |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004385006 |\n",
      "|    clip_fraction        | 0.0511      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.73        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    value_loss           | 6.89        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.1e+03      |\n",
      "|    ep_rew_mean          | 1.11e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 660          |\n",
      "|    total_timesteps      | 133120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032129898 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.304       |\n",
      "|    explained_variance   | 0.814        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49         |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    value_loss           | 6.91         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.1e+03      |\n",
      "|    ep_rew_mean          | 1.11e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 670          |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018510437 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.302       |\n",
      "|    explained_variance   | 0.829        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.09         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.00161     |\n",
      "|    value_loss           | 8.62         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.11e+03     |\n",
      "|    ep_rew_mean          | 1.12e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 680          |\n",
      "|    total_timesteps      | 137216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014200588 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.309       |\n",
      "|    explained_variance   | 0.861        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.62         |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.00205     |\n",
      "|    value_loss           | 8.17         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.11e+03     |\n",
      "|    ep_rew_mean          | 1.12e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 691          |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026055127 |\n",
      "|    clip_fraction        | 0.024        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.319       |\n",
      "|    explained_variance   | 0.837        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.39         |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    value_loss           | 8.16         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.12e+03     |\n",
      "|    ep_rew_mean          | 1.12e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 701          |\n",
      "|    total_timesteps      | 141312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064231222 |\n",
      "|    clip_fraction        | 0.0636       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.304       |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.05         |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.00632     |\n",
      "|    value_loss           | 2.15         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.12e+03     |\n",
      "|    ep_rew_mean          | 1.13e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 711          |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042642294 |\n",
      "|    clip_fraction        | 0.0745       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.298       |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.03         |\n",
      "|    n_updates            | 690          |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    value_loss           | 6.92         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.13e+03    |\n",
      "|    ep_rew_mean          | 1.13e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 721         |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007309096 |\n",
      "|    clip_fraction        | 0.0515      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.33        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.00451    |\n",
      "|    value_loss           | 6.76        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.13e+03     |\n",
      "|    ep_rew_mean          | 1.13e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 730          |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032233465 |\n",
      "|    clip_fraction        | 0.0355       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.292       |\n",
      "|    explained_variance   | 0.781        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.78         |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.00253     |\n",
      "|    value_loss           | 6.8          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.13e+03    |\n",
      "|    ep_rew_mean          | 1.13e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 741         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002918554 |\n",
      "|    clip_fraction        | 0.0273      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.73        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00128    |\n",
      "|    value_loss           | 7.25        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.14e+03     |\n",
      "|    ep_rew_mean          | 1.14e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 751          |\n",
      "|    total_timesteps      | 151552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052652317 |\n",
      "|    clip_fraction        | 0.06         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.291       |\n",
      "|    explained_variance   | 0.513        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.35         |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.00497     |\n",
      "|    value_loss           | 2.27         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.14e+03    |\n",
      "|    ep_rew_mean          | 1.14e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 761         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003883137 |\n",
      "|    clip_fraction        | 0.0506      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.279      |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.91        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    value_loss           | 6.75        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.15e+03     |\n",
      "|    ep_rew_mean          | 1.14e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 771          |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042581344 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.269       |\n",
      "|    explained_variance   | 0.83         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.78         |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.0013      |\n",
      "|    value_loss           | 6.41         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.15e+03     |\n",
      "|    ep_rew_mean          | 1.15e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 781          |\n",
      "|    total_timesteps      | 157696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026710625 |\n",
      "|    clip_fraction        | 0.0456       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.275       |\n",
      "|    explained_variance   | 0.829        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.01         |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    value_loss           | 7.68         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.16e+03     |\n",
      "|    ep_rew_mean          | 1.15e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 791          |\n",
      "|    total_timesteps      | 159744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030686813 |\n",
      "|    clip_fraction        | 0.0356       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.272       |\n",
      "|    explained_variance   | 0.822        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.18         |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    value_loss           | 6.9          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.16e+03    |\n",
      "|    ep_rew_mean          | 1.15e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 802         |\n",
      "|    total_timesteps      | 161792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003064759 |\n",
      "|    clip_fraction        | 0.0282      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.286      |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.00193    |\n",
      "|    value_loss           | 7.17        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.16e+03   |\n",
      "|    ep_rew_mean          | 1.15e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 201        |\n",
      "|    iterations           | 80         |\n",
      "|    time_elapsed         | 812        |\n",
      "|    total_timesteps      | 163840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00954813 |\n",
      "|    clip_fraction        | 0.0859     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.282     |\n",
      "|    explained_variance   | 0.506      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.27       |\n",
      "|    n_updates            | 790        |\n",
      "|    policy_gradient_loss | -0.00697   |\n",
      "|    value_loss           | 2.31       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.17e+03     |\n",
      "|    ep_rew_mean          | 1.16e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 822          |\n",
      "|    total_timesteps      | 165888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045738835 |\n",
      "|    clip_fraction        | 0.0345       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.269       |\n",
      "|    explained_variance   | 0.612        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.8          |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    value_loss           | 7.41         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.17e+03     |\n",
      "|    ep_rew_mean          | 1.16e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 832          |\n",
      "|    total_timesteps      | 167936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032992307 |\n",
      "|    clip_fraction        | 0.0402       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.257       |\n",
      "|    explained_variance   | 0.758        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.79         |\n",
      "|    n_updates            | 810          |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    value_loss           | 6.66         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.17e+03    |\n",
      "|    ep_rew_mean          | 1.16e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 842         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005911403 |\n",
      "|    clip_fraction        | 0.0367      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.789       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.86        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    value_loss           | 6.73        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.17e+03    |\n",
      "|    ep_rew_mean          | 1.16e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 852         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004431328 |\n",
      "|    clip_fraction        | 0.0302      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.252      |\n",
      "|    explained_variance   | 0.831       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.51        |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.00242    |\n",
      "|    value_loss           | 6.67        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.18e+03     |\n",
      "|    ep_rew_mean          | 1.17e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 862          |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043861642 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.255       |\n",
      "|    explained_variance   | 0.545        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.43         |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00543     |\n",
      "|    value_loss           | 3.02         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.18e+03     |\n",
      "|    ep_rew_mean          | 1.17e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 873          |\n",
      "|    total_timesteps      | 176128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027894378 |\n",
      "|    clip_fraction        | 0.0501       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.255       |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.75         |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.00529     |\n",
      "|    value_loss           | 6.38         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.19e+03    |\n",
      "|    ep_rew_mean          | 1.17e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 883         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002726286 |\n",
      "|    clip_fraction        | 0.0427      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.239      |\n",
      "|    explained_variance   | 0.84        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.69        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00196    |\n",
      "|    value_loss           | 6.37        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.19e+03     |\n",
      "|    ep_rew_mean          | 1.18e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 893          |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034610634 |\n",
      "|    clip_fraction        | 0.0349       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.255       |\n",
      "|    explained_variance   | 0.849        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.16         |\n",
      "|    n_updates            | 870          |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 7.57         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.19e+03     |\n",
      "|    ep_rew_mean          | 1.18e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 903          |\n",
      "|    total_timesteps      | 182272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037769775 |\n",
      "|    clip_fraction        | 0.0405       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.232       |\n",
      "|    explained_variance   | 0.868        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.792        |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    value_loss           | 6.65         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.2e+03      |\n",
      "|    ep_rew_mean          | 1.18e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 923          |\n",
      "|    total_timesteps      | 186368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064172433 |\n",
      "|    clip_fraction        | 0.0807       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.218       |\n",
      "|    explained_variance   | 0.563        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.45         |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    value_loss           | 2.92         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.2e+03      |\n",
      "|    ep_rew_mean          | 1.18e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 933          |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025305613 |\n",
      "|    clip_fraction        | 0.0369       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.217       |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4            |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    value_loss           | 7.04         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.21e+03     |\n",
      "|    ep_rew_mean          | 1.19e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 953          |\n",
      "|    total_timesteps      | 192512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051000714 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.229       |\n",
      "|    explained_variance   | 0.843        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.05         |\n",
      "|    n_updates            | 930          |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    value_loss           | 6.46         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.21e+03     |\n",
      "|    ep_rew_mean          | 1.19e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 201          |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 964          |\n",
      "|    total_timesteps      | 194560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035731117 |\n",
      "|    clip_fraction        | 0.0501       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.243       |\n",
      "|    explained_variance   | 0.846        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49         |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    value_loss           | 7.42         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.22e+03    |\n",
      "|    ep_rew_mean          | 1.2e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 201         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 984         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003044289 |\n",
      "|    clip_fraction        | 0.0494      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.242      |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.94        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    value_loss           | 6.43        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x23ee7b807d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol = \"EUR=\"\n",
    "features = [symbol, \"r\", \"s\", \"m\", \"v\"]\n",
    "window = 10\n",
    "lag = 5\n",
    "env = TradingEnv(symbol,features, window, lag )\n",
    "# model = DQN('MlpPolicy', env, verbose=1)\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=int(2e5), progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40e8bee2-6005-4990-be7a-0b11effca694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model_file_path = \"ppo_asset_trader_rl\"\n",
    "model.save(model_file_path)\n",
    "model_2 = PPO.load(model_file_path, env=env)\n",
    "mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06ece2ce-a2c1-45bc-aa60-021f154aed76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1481.349875)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ed7b23-7c8e-4211-83eb-b18654474c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf10c124-7bc8-4094-89d4-7b0e779104f3",
   "metadata": {},
   "source": [
    "#### Define the Deep Q-Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d4ea6-1d77-42ea-b364-4b03cfe57616",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \"\"\"\n",
    "    Specification for the DQN network\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        :param input_dim: Input dimension\n",
    "        :param output_dim: Output dimension\n",
    "        \"\"\"\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Neural net forward pass\n",
    "        :param x: Input\n",
    "        \"\"\"\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66d1e55-704e-4b25-882f-feef9b5bb816",
   "metadata": {},
   "source": [
    "#### RL DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bc0f16-d3f6-4b10-99ac-c6ebd73e1883",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    \"\"\"\n",
    "    DQN RL agent\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        state_dim: int, \n",
    "        action_dim: int):\n",
    "        \"\"\"\n",
    "        Cnstructor\n",
    "        :param state_dim: State dimension\n",
    "        :param action_dim: Action dimension\n",
    "        \"\"\"\n",
    "        self.model = DQN(state_dim, action_dim)\n",
    "        self.target_model = DQN(state_dim, action_dim)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=LEARNING_RATE)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.memory = deque(maxlen=REPLAY_EXPERIENCE_MEMORY_SIZE)\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.batch_size = 64\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        \"\"\"\n",
    "        Records the RL experience trajectories\n",
    "        :param state: State\n",
    "        :param action: Action\n",
    "        :param reward: Reward\n",
    "        :param next_state: Next state\n",
    "        :param done: Done\n",
    "        \"\"\"\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(\n",
    "        self, \n",
    "        state: np.ndarray\n",
    "    ) -> int:\n",
    "        \"\"\"\n",
    "        Invokes the agents 'act'\n",
    "        :param state: State\n",
    "        :return: action\n",
    "        \"\"\"\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(3)\n",
    "        state_tensor = torch.FloatTensor(state)\n",
    "        with torch.no_grad():\n",
    "            q_values = self.model(state_tensor)\n",
    "        return torch.argmax(q_values).item()\n",
    "\n",
    "    def replay(self):\n",
    "        \"\"\"\n",
    "        Experience replay\n",
    "        \"\"\"\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "\n",
    "        minibatch = random.sample(self.memory, self.batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            state_tensor = torch.FloatTensor(state)\n",
    "            next_state_tensor = torch.FloatTensor(next_state)\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target += self.gamma * torch.max(self.target_model(next_state_tensor)).item()\n",
    "\n",
    "            target_f = self.model(state_tensor)\n",
    "            target_f = target_f.clone().detach()\n",
    "            target_f[0, action] = target\n",
    "\n",
    "            self.model.train()\n",
    "            output = self.model(state_tensor)\n",
    "            loss = self.criterion(output, target_f)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "\n",
    "    def update_target_model(self):\n",
    "        \"\"\"\n",
    "        Updates the network model\n",
    "        \"\"\"\n",
    "        self.target_model.load_state_dict(self.model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9d4d17-ccd8-4fb4-8deb-4da1ebb8b765",
   "metadata": {},
   "source": [
    "#### Train the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f577f20-07cf-4384-ac50-f99e31c3b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAgent:\n",
    "    \"\"\"\n",
    "    Component used to train the RL agent\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        price_train_data: np.ndarray,\n",
    "        n_episodes: int=TRAINING_EPISODES_COUNT\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        :param price_train_data: Train data\n",
    "        :param n_episodes: Number of episodes for RL validation\n",
    "        \"\"\"\n",
    "        self.n_episodes = n_episodes\n",
    "        self.price_train_data = price_train_data\n",
    "        self.train_env = TradingEnv(self.price_train_data)\n",
    "        self.agent = DQNAgent(state_dim=self.price_train_data.shape[1], action_dim=3)\n",
    "        self.rewards = []\n",
    "        self.rewards_average = []\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs the RL agent training cycle\n",
    "        \"\"\"\n",
    "        for episodes in tqdm(range(self.n_episodes), desc=\"Episodes\"):\n",
    "            state, _ = self.train_env.reset()\n",
    "            total_reward = 0\n",
    "            done = False\n",
    "\n",
    "            for _ in range(len(self.price_train_data)):\n",
    "                action = self.agent.act(state)\n",
    "                next_state, reward, done, _, _ = self.train_env.step(action)\n",
    "                self.agent.remember(state, action, reward, next_state, done)\n",
    "                self.agent.replay()\n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "                self.rewards.append(total_reward)\n",
    "        \n",
    "                if done: \n",
    "                    average_reward = sum(self.rewards[-TRAINING_AVERAGE_ROLLING_WINDOW:]) / TRAINING_AVERAGE_ROLLING_WINDOW\n",
    "                    self.rewards_average.append(average_reward)\n",
    "                    break\n",
    "        \n",
    "            self.agent.update_target_model()\n",
    "            \n",
    "            #print(f\"Epoch {e+1}/{epochs}, Total Profit: {total_reward:.4f}, Epsilon: {self.agent.epsilon:.4f}\")\n",
    "\n",
    "        self.saveModel()\n",
    "\n",
    "    def saveModel(self):\n",
    "        \"\"\"\n",
    "        Save the neural net model\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        if os.path.exists(MODEL_FOLDER):\n",
    "            torch.save(self.agent.model, MODEL_FILE_PATH)\n",
    "            rewards_df = pd.DataFrame(self.rewards, columns=[\"rewards\"])\n",
    "            rewards_average_df = pd.DataFrame(self.rewards_average, columns=[\"average_rewards\"])\n",
    "            rewards_df.to_csv(TRAIN_REWARDS_FILE_PATH, index=False)\n",
    "            rewards_average_df.to_csv(TRAIN_AVERAGE_REWARDS_FILE_PATH, index=False)\n",
    "        else:\n",
    "            print(f\"The folder {MODEL_FOLDER} does not exist and the model could not be saved!!\")\n",
    "\n",
    "    def loadModel(self) -> DQN:\n",
    "        \"\"\"\n",
    "        Loads the neural net model\n",
    "        :return: Loaded model\n",
    "        \"\"\"\n",
    "        model = None\n",
    "        if os.path.exist(MODEL_FILE_PATH):\n",
    "            model = torch.load(MODEL_FILE_PATH)\n",
    "        else:\n",
    "            print(f\"The path {MODEL_FILE_PATH} does not exist and the model could not be loaded!!\")\n",
    "        return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20de9d97-afeb-467b-9a44-e9eae6bb0b23",
   "metadata": {},
   "source": [
    "#### Run the RL training cycle.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d9b9f7-62a7-4046-9938-5d8b64df4672",
   "metadata": {},
   "source": [
    "#### Validate/Test the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd74f92b-d2c3-44f2-9809-4e60c4f5ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Helpers.setSeeds()\n",
    "# train_agent = TrainAgent(price_train_data=close_data_train[:50])\n",
    "train_agent = TrainAgent(price_train_data=close_data_train)\n",
    "train_agent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1340aa67-f319-46e7-ba7d-8be3806aad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidateAgent:\n",
    "    \"\"\"\n",
    "    Component used to validate/test the RL agent\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        price_test_data: np.ndarray,\n",
    "        n_episodes: int=TEST_EPISODES_COUNT\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        :param price_test_data: Test data\n",
    "        :param n_episodes: Number of episodes for RL validation/test\n",
    "        \"\"\"\n",
    "        self.n_episodes = n_episodes\n",
    "        self.price_test_data = price_test_data\n",
    "        self.test_env = TradingEnv(self.price_train_data)\n",
    "        self.agent = DQNAgent(state_dim=1, action_dim=3)\n",
    "        self.reward = []\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Runs the RL agent validation/test cycle\n",
    "        \"\"\"\n",
    "        self.agent.epsilon = 0.0  # Turn off exploration\n",
    "        for episodes in range(self.n_episodes):\n",
    "            state, _ = self.test_env.reset()\n",
    "            total_reward = 0\n",
    "            done = False\n",
    "            while not done:\n",
    "                action = self.agent.act(state)\n",
    "                next_state, reward, done, _, _ = self.test_env.step(action)\n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "\n",
    "            self.rewards.append(total_reward)\n",
    "            print(f\"Epoch {e+1}/{epochs}, Total Profit: {total_reward:.4f}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64174cf7-368d-4382-80b4-aaf7052769c2",
   "metadata": {},
   "source": [
    "#### Report RL performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec946afe-839f-4745-acf9-9da62df27157",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportRLPerformance:\n",
    "    \"\"\"\n",
    "    Component used to report the RL performance\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_rewards: List[float],\n",
    "        train_rewards_average: List[float]\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        :param train_rewards: Training rewards\n",
    "        :param train_rewards_average: Validation rewards\n",
    "        \"\"\"\n",
    "        self.train_rewards = train_rewards\n",
    "        self.train_rewards_average = train_rewards_average\n",
    "\n",
    "    def plotRewardCurves(\n",
    "        self,\n",
    "        rewards: List[float],\n",
    "        plot_type: str\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Plots the reward curves\n",
    "        :param rewards: Rewards\n",
    "        :param plot_type: Plot type\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        plt.plot(rewards)\n",
    "        plt.xlabel(\"Episode\")\n",
    "        plt.ylabel(\"Total Profit\")\n",
    "        plt.title(f\"{plot_type} Reward Progress\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def plotTrainingRewardCurves(\n",
    "        self,\n",
    "        plot_type: str = \"Training\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Plots the training reward curves\n",
    "        :param plot_type: Plot type\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.plotRewardCurves(self.train_rewards, plot_type=plot_type)\n",
    "\n",
    "    def plotsmoothedTrainingRewardCurves(\n",
    "        self,\n",
    "        plot_type: str = \"Smoothed Training\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Plots the training reward curves\n",
    "        :param plot_type: Plot type\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.plotRewardCurves(self.train_rewards_average, plot_type=plot_type)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ffbb0c-fa12-41e0-8e9e-b6c430062d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reporter = ReportRLPerformance(train_rewards = train_agent.rewards, train_rewards_average=train_agent.rewards_average)\n",
    "reporter.plotTrainingRewardCurves()\n",
    "reporter.plotsmoothedTrainingRewardCurves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81572ba8-b3ab-416d-b97e-6dafdc9f433e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2ba029-4759-4fd8-9a0e-072828fb3243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358872d2-b4b5-40cb-87e7-f1e8565489f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128cb71f-d99a-4e85-85fe-8f67673825c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07859cff-6d4e-4cd7-81fd-e2669d150680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo():\n",
    "    trewards = []\n",
    "    for _ in range(10):\n",
    "        \n",
    "        treward = _ + 1\n",
    "        trewards.append(treward)\n",
    "        print(trewards)\n",
    "\n",
    "\n",
    "foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5bae5c-0805-4641-8d27-4972579e675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = list(range(100))\n",
    "t[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5750fd25-ee3c-4389-a393-502ebcd9aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame({\"prices\": range(100)})\n",
    "df_1.rolling(10).sum().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544cdd5c-4bd7-4f53-83b2-7f712b13e6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.11) rl_env",
   "language": "python",
   "name": "rl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
