2025-06-05 08:20:13,973 - INFO - rl_algo_trading_agent.py:_createAlgoTradingEnvironments - : Creating the 'train' RL algo trading environment.. in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:135
2025-06-05 08:20:13,989 - INFO - rl_algo_trading_agent.py:_createAlgoTradingEnvironments - : Creating the 'test' RL algo trading environment.. in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:138
2025-06-05 08:20:14,005 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-05 08:20:14,006 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-05 08:20:14,007 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 08:20:14,008 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 08:20:16,003 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.dqn algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 08:20:16,018 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_dqn\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 08:20:18,637 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 08:24:38,881 - INFO - rl_algo_trading_agent.py:_createAlgoTradingEnvironments - : Creating the 'train' RL algo trading environment.. in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:135
2025-06-05 08:24:38,895 - INFO - rl_algo_trading_agent.py:_createAlgoTradingEnvironments - : Creating the 'test' RL algo trading environment.. in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:138
2025-06-05 08:24:38,918 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 08:24:38,919 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 08:24:38,920 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 08:24:38,920 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 08:25:00,119 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 08:25:00,130 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 08:25:03,059 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 08:25:05,668 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 14:57:57,749 - INFO - rl_algo_trading_agent.py:_createAlgoTradingEnvironments - : Creating the 'train' RL algo trading environment.. in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:136
2025-06-05 14:57:57,756 - INFO - rl_algo_trading_agent.py:_createAlgoTradingEnvironments - : Creating the 'test' RL algo trading environment.. in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:139
2025-06-05 14:57:57,777 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:57
2025-06-05 14:57:57,778 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:58
2025-06-05 14:57:57,779 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 14:57:57,780 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 14:57:59,790 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 14:57:59,806 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 14:58:02,943 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 17:52:09,197 - INFO - rl_algo_trading_agent.py:_createAlgoTradingEnvironments - : Creating the 'train' RL algo trading environment.. in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:136
2025-06-05 17:52:09,210 - INFO - rl_algo_trading_agent.py:_createAlgoTradingEnvironments - : Creating the 'test' RL algo trading environment.. in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:139
2025-06-05 17:52:09,225 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:57
2025-06-05 17:52:09,225 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:58
2025-06-05 17:52:09,227 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 17:52:09,227 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 17:55:22,760 - INFO - rl_algo_trading_agent.py:_createAlgoTradingEnvironments - : Creating the 'train' RL algo trading environment.. in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:136
2025-06-05 17:55:22,766 - INFO - rl_algo_trading_agent.py:_createAlgoTradingEnvironments - : Creating the 'test' RL algo trading environment.. in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:139
2025-06-05 17:55:22,784 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:57
2025-06-05 17:55:22,790 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:58
2025-06-05 17:55:22,790 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 17:55:22,792 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 17:57:23,429 - INFO - rl_algo_trading_agent.py:_createAlgoTradingEnvironments - : Creating the 'train' RL algo trading environment.. in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:136
2025-06-05 17:57:23,447 - INFO - rl_algo_trading_agent.py:_createAlgoTradingEnvironments - : Creating the 'test' RL algo trading environment.. in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:139
2025-06-05 17:57:23,463 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:57
2025-06-05 17:57:23,463 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:58
2025-06-05 17:57:23,463 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 17:57:23,463 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 17:57:28,726 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 17:57:28,737 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 17:57:32,178 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 18:00:32,314 - INFO - rl_algo_trading_agent.py:_createAlgoTradingEnvironments - : Creating the 'train' RL algo trading environment.. in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:136
2025-06-05 18:00:32,329 - INFO - rl_algo_trading_agent.py:_createAlgoTradingEnvironments - : Creating the 'test' RL algo trading environment.. in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:139
2025-06-05 18:00:32,337 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:57
2025-06-05 18:00:32,346 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:58
2025-06-05 18:00:32,346 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 18:00:32,346 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 18:00:34,908 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 18:00:34,916 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 18:00:38,571 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 18:02:06,265 - INFO - rl_algo_trading_agent.py:_createAlgoTradingEnvironments - : Creating the 'train' RL algo trading environment.. in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:136
2025-06-05 18:02:06,280 - INFO - rl_algo_trading_agent.py:_createAlgoTradingEnvironments - : Creating the 'test' RL algo trading environment.. in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:139
2025-06-05 18:02:06,286 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:57
2025-06-05 18:02:06,295 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:58
2025-06-05 18:02:06,295 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 18:02:06,297 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 18:02:10,409 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 18:02:10,420 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 18:02:14,211 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 18:08:24,406 - INFO - rl_algo_trading_agent.py:_createAlgoTradingEnvironments - : Creating the 'train' RL algo trading environment.. in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:136
2025-06-05 18:08:24,429 - INFO - rl_algo_trading_agent.py:_createAlgoTradingEnvironments - : Creating the 'test' RL algo trading environment.. in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:139
2025-06-05 18:08:24,441 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:57
2025-06-05 18:08:24,441 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:58
2025-06-05 18:08:24,441 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 18:08:24,441 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 18:29:44,578 - INFO - rl_algo_trading_agent.py:_createAlgoTradingEnvironments - : Creating the 'train' RL algo trading environment.. in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:136
2025-06-05 18:29:44,581 - INFO - rl_algo_trading_agent.py:_createAlgoTradingEnvironments - : Creating the 'test' RL algo trading environment.. in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:139
2025-06-05 18:29:44,602 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:57
2025-06-05 18:29:44,602 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:58
2025-06-05 18:29:44,610 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 18:29:44,610 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 18:29:46,552 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 18:29:46,563 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 18:29:50,118 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\notebooks\..\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
