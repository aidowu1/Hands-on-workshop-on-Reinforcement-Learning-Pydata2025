2025-06-05 06:59:32,270 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 06:59:32,271 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 06:59:32,271 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 06:59:32,272 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 06:59:34,167 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:39
2025-06-05 06:59:34,179 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/Pendulum-v1_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 06:59:36,869 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 07:14:07,725 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 07:14:07,729 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 07:14:07,733 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 07:14:07,737 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 07:14:10,503 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:39
2025-06-05 07:14:10,535 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/Pendulum-v1_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 07:19:56,578 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 07:19:56,578 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 07:19:56,578 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 07:19:56,579 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 07:19:58,383 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:39
2025-06-05 07:19:58,395 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/Pendulum-v1_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 07:20:01,103 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 07:20:09,126 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 07:25:54,763 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 07:25:54,763 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 07:25:54,763 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 07:25:54,763 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 07:25:57,582 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:39
2025-06-05 07:25:57,597 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/Pendulum-v1_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 07:26:04,519 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 07:26:10,413 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 07:34:13,281 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 07:34:13,281 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 07:34:13,282 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 07:34:13,282 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 07:34:15,139 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:39
2025-06-05 07:34:15,151 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/Pendulum-v1_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 07:36:10,148 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 07:36:10,148 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 07:36:10,149 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 07:36:10,149 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 07:36:11,992 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:39
2025-06-05 07:36:12,003 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/Pendulum-v1_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 07:36:14,731 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 07:36:16,941 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 07:37:31,265 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 07:37:31,265 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 07:37:31,265 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 07:37:31,265 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 07:37:34,006 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:39
2025-06-05 07:37:34,030 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/Pendulum-v1_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 07:37:41,071 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 07:46:00,242 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 07:46:00,243 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 07:46:00,243 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 07:46:00,243 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 07:46:02,125 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:39
2025-06-05 07:46:02,135 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/Pendulum-v1_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 07:46:04,932 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 07:46:07,089 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 08:02:37,236 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 08:02:37,236 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 08:02:37,236 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 08:02:37,252 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 08:02:40,024 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 08:02:40,055 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 08:18:03,221 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 08:18:03,221 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 08:18:03,222 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 08:18:03,223 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 08:18:05,048 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 08:18:05,061 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 08:18:08,184 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 08:18:13,659 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 08:18:16,484 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 08:30:14,653 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 08:30:14,654 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 08:30:14,654 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 08:30:14,654 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 08:30:16,509 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 08:30:16,522 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 08:30:19,694 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 08:33:20,296 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 08:33:20,296 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 08:33:20,296 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 08:33:20,296 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 08:33:23,104 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 08:33:23,124 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 08:33:47,351 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 08:34:00,693 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 09:46:50,253 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 09:46:50,254 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 09:46:50,254 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 09:46:50,254 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 09:46:52,127 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 09:46:52,139 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 09:46:55,231 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 09:46:57,909 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 09:49:24,211 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 09:49:24,211 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 09:49:24,211 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 09:49:24,212 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 09:49:26,012 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 09:49:26,025 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 09:49:29,116 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 09:54:34,873 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 09:54:34,873 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 09:54:34,873 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 09:54:34,873 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 09:54:37,518 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 09:54:37,534 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 09:54:45,103 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 10:36:44,278 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 10:36:44,278 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 10:36:44,278 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 10:36:44,279 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 10:36:46,089 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 10:36:46,101 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 10:36:49,174 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 10:39:06,393 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 10:39:06,393 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 10:39:06,394 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 10:39:06,394 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 10:39:08,179 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 10:39:08,191 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 10:39:11,325 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 10:41:28,491 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 10:41:28,507 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 10:41:28,507 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 10:41:28,507 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 10:41:31,144 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 10:41:31,164 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 10:41:38,641 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 10:41:45,519 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 10:41:52,348 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 10:41:59,153 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 10:59:20,456 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 10:59:20,457 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 10:59:20,457 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 10:59:20,457 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 10:59:22,271 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 10:59:22,284 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 10:59:25,361 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 11:41:55,019 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 11:41:55,019 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 11:41:55,020 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-05 11:41:55,020 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 11:41:56,831 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 11:41:56,843 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 11:41:59,938 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 11:42:02,658 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 11:45:41,753 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 11:45:41,753 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 11:45:41,755 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 11:45:41,755 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 11:45:43,535 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 11:45:43,548 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 11:45:46,646 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 11:57:15,622 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 11:57:15,622 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 11:57:15,623 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:118
2025-06-05 11:57:15,623 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 11:57:17,381 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 11:57:17,391 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 11:57:20,459 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 11:57:23,192 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 11:57:25,958 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 13:05:27,337 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 13:05:27,337 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 13:05:27,337 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 13:05:27,338 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 13:05:29,271 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 13:05:29,284 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 13:06:53,611 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 13:06:53,611 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 13:06:53,612 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 13:06:53,612 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 13:06:55,387 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 13:06:55,396 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 13:08:44,717 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 13:08:44,717 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 13:08:44,717 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 13:08:44,718 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 13:08:46,536 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 13:08:46,549 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 13:13:12,735 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 13:13:12,735 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 13:13:12,735 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 13:13:12,736 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 13:13:14,564 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 13:13:14,576 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 13:18:02,713 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 13:18:02,713 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 13:18:02,713 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 13:18:02,714 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 13:18:04,534 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 13:18:04,547 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 13:18:41,348 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 13:18:41,348 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 13:18:41,348 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 13:18:41,348 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 13:18:49,550 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 13:26:17,083 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:57
2025-06-05 13:26:17,083 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:58
2025-06-05 13:26:17,083 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 13:26:17,083 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 13:26:18,863 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 13:26:18,878 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 13:26:21,942 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 13:26:24,665 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 13:29:24,726 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:57
2025-06-05 13:29:24,727 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:58
2025-06-05 13:29:24,727 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 13:29:24,727 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 13:29:26,541 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 13:29:26,554 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 13:29:29,559 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 13:29:32,273 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 13:39:49,357 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:57
2025-06-05 13:39:49,357 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:58
2025-06-05 13:39:49,357 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 13:39:49,358 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 13:39:51,151 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 13:39:51,162 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 13:39:54,552 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 13:45:08,959 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:57
2025-06-05 13:45:08,959 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:58
2025-06-05 13:45:08,959 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 13:45:08,960 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 13:45:10,692 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 13:45:10,705 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 13:45:45,404 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:57
2025-06-05 13:45:45,404 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:58
2025-06-05 13:45:45,405 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 13:45:45,405 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 13:45:47,159 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 13:45:47,172 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 13:45:50,232 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 13:47:19,595 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:57
2025-06-05 13:47:19,595 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:58
2025-06-05 13:47:19,609 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 13:47:19,611 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 13:48:00,476 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 13:48:00,491 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 13:48:08,044 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 13:53:38,525 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:57
2025-06-05 13:53:38,525 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:58
2025-06-05 13:53:38,526 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 13:53:38,526 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 13:53:40,345 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 13:53:40,357 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 13:53:43,440 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 13:54:38,919 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:57
2025-06-05 13:54:38,920 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:58
2025-06-05 13:54:38,920 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 13:54:38,920 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 13:54:40,719 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 13:54:40,731 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 13:54:43,841 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 13:54:46,576 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 13:56:06,800 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:57
2025-06-05 13:56:06,800 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:58
2025-06-05 13:56:06,800 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 13:56:06,800 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 13:56:08,597 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 13:56:08,609 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 13:56:11,714 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 13:57:43,649 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:57
2025-06-05 13:57:43,649 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:58
2025-06-05 13:57:43,649 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 13:57:43,650 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 13:57:45,427 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 13:57:45,439 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 13:57:48,504 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 13:59:00,684 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:57
2025-06-05 13:59:00,684 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:58
2025-06-05 13:59:00,685 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 13:59:00,685 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 13:59:02,496 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 13:59:02,508 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 13:59:05,542 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 14:51:51,933 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:57
2025-06-05 14:51:51,933 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:58
2025-06-05 14:51:51,933 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 14:51:51,934 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 14:51:53,733 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 14:51:53,746 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 14:51:56,859 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 14:52:43,542 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:57
2025-06-05 14:52:43,543 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:58
2025-06-05 14:52:43,543 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 14:52:43,543 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 14:52:45,317 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.ppo algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 14:52:45,330 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 14:52:48,317 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 14:54:13,141 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-05 14:54:13,141 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-05 14:54:13,142 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 14:54:13,142 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 14:54:14,873 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.dqn algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 14:54:14,886 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_dqn\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 14:54:17,487 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 18:14:36,169 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-05 18:14:36,169 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-05 18:14:36,169 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 18:14:36,169 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 18:20:55,958 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-05 18:20:55,958 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-05 18:20:55,958 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 18:20:55,958 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 18:20:58,839 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.dqn algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:44
2025-06-05 18:20:58,915 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/RL-Algo-Trader_dqn\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-05 18:21:07,108 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/RL-Algo-Trader_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-05 18:21:47,387 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-05 18:21:47,389 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-05 18:21:47,391 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 18:21:47,393 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 18:24:21,009 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-05 18:24:21,011 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-05 18:24:21,011 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 18:24:21,011 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 18:26:49,896 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-05 18:26:49,896 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-05 18:26:49,896 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 18:26:49,896 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 18:28:36,730 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-05 18:28:36,731 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-05 18:28:36,731 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 18:28:36,731 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
2025-06-05 18:57:37,605 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: RL-ALGO-TRADER in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-05 18:57:37,606 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-05 18:57:37,606 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:119
2025-06-05 18:57:37,606 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:120
