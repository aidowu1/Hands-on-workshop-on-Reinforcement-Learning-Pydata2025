2025-06-03 13:26:24,658 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V0 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-03 13:26:24,660 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-03 13:26:24,662 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-03 13:26:24,664 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-03 14:22:55,602 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V0 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-03 14:22:55,602 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-03 14:22:55,602 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-03 14:22:55,602 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-03 21:48:20,917 - INFO - rl_algo_trading_agent.py:train - : Training RL algo trading agent with the RLAgorithmType.dqn algorithm in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_agents\rl_algo_trading_agent.py:39
2025-06-03 21:48:20,937 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/CartPole-v0_dqn\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:47
2025-06-03 21:48:30,155 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-03 21:48:40,031 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-03 21:48:52,333 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-03 21:49:05,229 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-03 21:50:32,571 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-03 21:51:10,612 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-03 21:51:47,300 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-03 21:52:24,025 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-03 22:17:13,196 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-03 22:19:49,851 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-03 22:20:26,677 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-03 22:21:03,940 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-03 22:21:29,965 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-03 22:21:39,960 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-03 22:23:40,929 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-03 22:24:16,814 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-03 22:24:53,843 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-03 22:25:30,265 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-03 22:26:07,140 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:68
2025-06-03 23:25:03,111 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V0 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-03 23:25:03,114 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-03 23:25:03,116 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-03 23:25:03,118 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-03 23:29:22,800 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V0 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-03 23:29:22,800 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-03 23:29:22,800 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-03 23:29:22,800 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\rl-robo-algo-trader\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
