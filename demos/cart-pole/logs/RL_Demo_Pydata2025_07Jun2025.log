2025-06-07 00:06:58,079 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-07 00:06:58,080 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-07 00:06:58,086 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-07 00:06:58,086 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-07 00:29:39,178 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-07 00:29:39,178 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-07 00:29:39,179 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-07 00:29:39,179 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-07 09:46:56,209 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-07 09:46:56,209 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-07 09:46:56,211 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-07 09:46:56,211 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-07 09:49:57,779 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-07 09:49:57,779 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-07 09:49:57,779 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-07 09:49:57,779 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-07 09:51:40,130 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-07 09:51:40,137 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-07 09:51:40,139 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-07 09:51:40,139 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-07 09:59:46,275 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-07 09:59:46,279 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-07 09:59:46,285 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-07 09:59:46,285 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-07 19:23:29,961 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-07 19:23:29,962 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-07 19:23:29,962 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-07 19:23:29,963 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-07 19:23:32,040 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/CartPole-v1_dqn\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:45
2025-06-07 19:23:32,559 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:23:49,090 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:23:50,485 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:23:51,295 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:23:52,116 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:23:52,972 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:23:59,901 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:00,735 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:01,574 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:02,413 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:03,297 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:07,676 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:08,497 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:09,320 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:10,130 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:11,007 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:11,833 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:12,644 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:13,446 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:14,279 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:15,117 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:16,155 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:16,990 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:17,813 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:18,674 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:19,484 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:20,281 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:21,080 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:21,884 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:26,075 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:26,879 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:27,737 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:24:28,621 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:31:33,812 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-07 19:31:33,812 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-07 19:31:33,813 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-07 19:31:33,813 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'batch_size': 64, 'gamma': 0.99, 'gae_lambda': 0.9, 'ent_coef': 0.0, 'sde_sample_freq': 4, 'max_grad_norm': 0.5, 'vf_coef': 0.5, 'learning_rate': 3e-05, 'use_sde': True, 'policy_kwargs': {'log_std_init': -2.7, 'ortho_init': False, 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>, 'net_arch': {'pi': [256, 256], 'vf': [256, 256]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-07 19:34:55,027 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-07 19:34:55,028 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-07 19:34:55,029 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-07 19:34:55,029 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'batch_size': 64, 'gamma': 0.99, 'gae_lambda': 0.9, 'ent_coef': 0.0, 'sde_sample_freq': 4, 'max_grad_norm': 0.5, 'vf_coef': 0.5, 'learning_rate': 3e-05, 'use_sde': False, 'policy_kwargs': {'log_std_init': -2.7, 'ortho_init': False, 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>, 'net_arch': {'pi': [256, 256], 'vf': [256, 256]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-07 19:35:51,299 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-07 19:35:51,300 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-07 19:35:51,300 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-07 19:35:51,301 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'batch_size': 64, 'gamma': 0.99, 'gae_lambda': 0.9, 'ent_coef': 0.0, 'sde_sample_freq': 4, 'max_grad_norm': 0.5, 'vf_coef': 0.5, 'learning_rate': 3e-05, 'use_sde': False, 'policy_kwargs': {'log_std_init': -2.7, 'ortho_init': False, 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>, 'net_arch': {'pi': [256, 256], 'vf': [256, 256]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-07 19:35:53,288 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/Pendulum-v1_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:45
2025-06-07 19:35:53,898 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:35:56,174 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:35:56,802 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:35:58,474 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:35:59,034 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:36:00,829 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:36:01,379 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:36:03,111 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:36:03,679 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:50:50,345 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-07 19:50:50,346 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-07 19:50:50,346 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-07 19:50:50,346 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'batch_size': 64, 'gamma': 0.99, 'gae_lambda': 0.9, 'ent_coef': 0.0, 'sde_sample_freq': 4, 'max_grad_norm': 0.5, 'vf_coef': 0.5, 'learning_rate': 3e-05, 'use_sde': False, 'policy_kwargs': {'log_std_init': -2.7, 'ortho_init': False, 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>, 'net_arch': {'pi': [256, 256], 'vf': [256, 256]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-07 19:50:52,265 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/CartPole-v1_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:45
2025-06-07 19:50:52,825 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:50:55,126 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:50:55,700 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:50:57,422 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:50:57,993 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:50:59,676 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:51:00,212 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:51:01,936 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 19:51:02,571 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 20:52:13,649 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-07 20:52:13,650 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-07 20:52:13,651 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-07 20:52:13,651 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'batch_size': 64, 'gamma': 0.99, 'gae_lambda': 0.9, 'ent_coef': 0.0, 'sde_sample_freq': 4, 'max_grad_norm': 0.5, 'vf_coef': 0.5, 'learning_rate': 3e-05, 'use_sde': False, 'policy_kwargs': {'log_std_init': -2.7, 'ortho_init': False, 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>, 'net_arch': {'pi': [256, 256], 'vf': [256, 256]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-07 20:52:15,800 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/CartPole-v1_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:45
2025-06-07 20:52:16,350 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 20:52:18,700 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 20:52:19,280 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 20:52:20,943 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 20:52:21,491 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 20:52:23,109 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 20:52:23,634 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 20:52:25,348 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 20:52:25,908 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-07 20:53:20,098 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-07 20:53:20,100 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-07 20:53:20,100 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-07 20:53:20,101 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'batch_size': 64, 'gamma': 0.99, 'gae_lambda': 0.9, 'ent_coef': 0.0, 'sde_sample_freq': 4, 'max_grad_norm': 0.5, 'vf_coef': 0.5, 'learning_rate': 3e-05, 'use_sde': False, 'policy_kwargs': {'log_std_init': -2.7, 'ortho_init': False, 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>, 'net_arch': {'pi': [256, 256], 'vf': [256, 256]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-07 20:57:34,414 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-07 20:57:34,414 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-07 20:57:34,415 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-07 20:57:34,415 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'batch_size': 64, 'gamma': 0.99, 'gae_lambda': 0.9, 'ent_coef': 0.0, 'sde_sample_freq': 4, 'max_grad_norm': 0.5, 'vf_coef': 0.5, 'learning_rate': 3e-05, 'use_sde': False, 'policy_kwargs': {'log_std_init': -2.7, 'ortho_init': False, 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>, 'net_arch': {'pi': [256, 256], 'vf': [256, 256]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-07 20:59:22,439 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-07 20:59:22,440 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-07 20:59:22,441 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-07 20:59:22,441 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-07 21:01:10,855 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-07 21:01:10,855 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-07 21:01:10,856 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-07 21:01:10,856 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-07 21:23:36,245 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-07 21:23:36,245 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-07 21:23:36,245 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-07 21:23:36,246 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'batch_size': 64, 'gamma': 0.99, 'gae_lambda': 0.9, 'ent_coef': 0.0, 'sde_sample_freq': 4, 'max_grad_norm': 0.5, 'vf_coef': 0.5, 'learning_rate': 3e-05, 'use_sde': False, 'policy_kwargs': {'log_std_init': -2.7, 'ortho_init': False, 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>, 'net_arch': {'pi': [256, 256], 'vf': [256, 256]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-07 21:24:48,595 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-07 21:24:48,595 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-07 21:24:48,595 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-07 21:24:48,596 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\repo\Hands-on-workshop-on-Reinforcement-Learning-Pydata2025\demos\cart-pole\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
