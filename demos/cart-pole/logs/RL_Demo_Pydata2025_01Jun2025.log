2025-06-01 14:01:06,566 - INFO - ddpg_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:43
2025-06-01 14:01:06,566 - INFO - ddpg_algorithm.py:__init__ - : This RL environment uses a DDPG RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:44
2025-06-01 14:01:06,567 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 14:01:06,567 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 14:12:10,951 - INFO - ddpg_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:43
2025-06-01 14:12:10,951 - INFO - ddpg_algorithm.py:__init__ - : This RL environment uses a DDPG RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:44
2025-06-01 14:12:10,952 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 14:12:10,952 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 15:47:48,606 - INFO - ddpg_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:43
2025-06-01 15:47:48,606 - INFO - ddpg_algorithm.py:__init__ - : This RL environment uses a DDPG RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:44
2025-06-01 15:47:48,606 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 15:47:48,607 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 15:47:50,442 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/Pendulum-v1_ddpg\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:45
2025-06-01 15:47:50,873 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:13,739 - INFO - ddpg_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:43
2025-06-01 15:49:13,740 - INFO - ddpg_algorithm.py:__init__ - : This RL environment uses a DDPG RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:44
2025-06-01 15:49:13,740 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 15:49:13,740 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 15:49:15,529 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/Pendulum-v1_ddpg\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:45
2025-06-01 15:49:15,963 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:29,458 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:30,376 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:31,245 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:32,161 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:33,034 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:33,924 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:34,818 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:35,672 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:36,578 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:37,495 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:38,384 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:39,305 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:45,483 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:46,403 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:47,316 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:48,210 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:49,161 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:50,166 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:51,197 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:52,227 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:53,195 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:54,190 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:55,181 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:56,187 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:57,169 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:58,132 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:49:59,125 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:00,085 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:01,073 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:02,041 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:03,043 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:04,037 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:05,029 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:06,009 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:06,994 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:07,971 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:08,918 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:09,882 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:10,861 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:11,837 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:12,817 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:13,802 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:14,814 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:15,800 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:16,790 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:17,769 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:18,768 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:19,749 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:20,760 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:21,742 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:22,748 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:23,714 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:24,710 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:25,703 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:26,685 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:27,650 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:28,666 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:29,645 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:30,655 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:31,692 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:32,695 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:33,679 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:34,682 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:35,661 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:36,662 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:37,636 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:38,647 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:39,615 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:40,588 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:41,573 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:42,584 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:43,598 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:44,588 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:45,586 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:46,590 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:47,592 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:48,607 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:49,625 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:50,619 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:51,636 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:52,609 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:53,629 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:54,633 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:55,640 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:56,646 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:57,660 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:58,663 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:50:59,666 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:51:00,666 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:51:01,683 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:51:02,711 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:51:03,711 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:51:04,719 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:51:05,728 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:51:06,771 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:51:10,740 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:51:11,734 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:51:12,758 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:51:13,766 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:51:14,857 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:54:13,647 - INFO - ddpg_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:43
2025-06-01 15:54:13,647 - INFO - ddpg_algorithm.py:__init__ - : This RL environment uses a DDPG RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:44
2025-06-01 15:54:13,648 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 15:54:13,648 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 15:54:15,348 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/Pendulum-v1_ddpg\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:45
2025-06-01 15:54:17,008 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:54:19,145 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:54:21,241 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:54:23,356 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:54:26,598 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:54:29,082 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:54:31,494 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:54:33,894 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:54:36,267 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:54:38,672 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:54:41,042 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:54:43,433 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:54:45,814 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:54:48,222 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:54:50,702 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:54:53,616 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:54:56,396 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:54:59,310 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:02,115 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:05,089 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:08,020 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:10,794 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:14,434 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:17,135 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:19,280 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:21,581 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:23,984 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:26,402 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:28,829 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:31,236 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:33,620 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:35,991 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:38,375 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:40,721 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:43,145 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:45,705 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:48,201 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:50,599 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:52,997 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:55,383 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:55:57,744 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:56:00,143 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:56:02,511 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:56:05,188 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:56:07,751 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:56:11,493 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:56:15,442 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:56:19,637 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:56:23,749 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:56:26,952 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:56:30,980 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:56:34,949 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:56:42,667 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:56:51,032 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:56:55,063 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 15:57:18,373 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 16:09:40,629 - INFO - ddpg_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:44
2025-06-01 16:09:40,629 - INFO - ddpg_algorithm.py:__init__ - : This RL environment uses a DDPG RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:45
2025-06-01 16:09:40,629 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 16:09:40,630 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 16:09:42,408 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/Pendulum-v1_ddpg\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:45
2025-06-01 16:09:44,017 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 16:09:54,603 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 16:09:56,771 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 16:09:58,957 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 16:10:01,155 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 16:10:05,616 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 16:10:07,845 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 16:10:10,090 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 16:10:12,327 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 16:10:14,601 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 16:10:16,825 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 16:10:19,077 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 16:10:21,474 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 16:10:23,882 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 16:10:26,303 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 16:53:04,241 - INFO - td3_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\td3_algorithm.py:49
2025-06-01 16:53:04,241 - INFO - td3_algorithm.py:__init__ - : This RL environment uses a TD3 RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\td3_algorithm.py:50
2025-06-01 16:53:04,242 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 16:53:04,242 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 17:40:57,510 - INFO - td3_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\td3_algorithm.py:49
2025-06-01 17:40:57,510 - INFO - td3_algorithm.py:__init__ - : This RL environment uses a TD3 RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\td3_algorithm.py:50
2025-06-01 17:40:57,510 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 17:40:57,510 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 17:40:59,395 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/Pendulum-v1_td3\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:45
2025-06-01 17:41:01,108 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_td3\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:41:17,405 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_td3\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:41:20,130 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_td3\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:41:22,807 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_td3\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:41:25,510 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_td3\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:41:28,169 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_td3\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:41:30,906 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_td3\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:41:33,644 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_td3\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:41:36,333 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_td3\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:41:38,985 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_td3\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:41:41,600 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_td3\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:41:44,313 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_td3\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:41:46,904 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_td3\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:41:49,531 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_td3\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:47:50,448 - INFO - sac_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\sac_algorithm.py:47
2025-06-01 17:47:50,449 - INFO - sac_algorithm.py:__init__ - : This RL environment uses a SAC RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\sac_algorithm.py:48
2025-06-01 17:47:50,449 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 17:47:50,449 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9, 'learning_rate': 0.004843759072455456, 'batch_size': 1024, 'buffer_size': 10000, 'learning_starts': 1000, 'train_freq': 16, 'tau': 0.005, 'policy_kwargs': {'log_std_init': 0.2571311109643921, 'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 17:48:09,466 - INFO - sac_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\sac_algorithm.py:47
2025-06-01 17:48:09,466 - INFO - sac_algorithm.py:__init__ - : This RL environment uses a SAC RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\sac_algorithm.py:48
2025-06-01 17:48:09,466 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 17:48:09,467 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9, 'learning_rate': 0.004843759072455456, 'batch_size': 1024, 'buffer_size': 10000, 'learning_starts': 1000, 'train_freq': 16, 'tau': 0.005, 'policy_kwargs': {'log_std_init': 0.2571311109643921, 'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 17:48:11,389 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/Pendulum-v1_sac\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:45
2025-06-01 17:48:11,452 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:48:11,537 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:48:52,774 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:48:53,442 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:48:54,085 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:48:54,728 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:48:55,418 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:48:56,079 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:48:56,735 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:48:57,407 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:48:58,058 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:48:58,713 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:48:59,369 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:49:00,061 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:49:01,145 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:49:01,757 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:49:02,408 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:49:03,067 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:49:03,772 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:49:04,364 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:49:04,994 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:49:05,689 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:49:06,329 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:49:06,947 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:49:07,594 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:49:08,254 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:49:08,914 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:49:09,552 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:49:10,209 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:49:10,863 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:49:11,528 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:49:12,183 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:49:12,831 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:49:13,473 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_sac\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:54:29,823 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-01 17:54:29,823 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-01 17:54:29,823 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 17:54:29,824 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'batch_size': 64, 'gamma': 0.99, 'gae_lambda': 0.9, 'ent_coef': 0.0, 'sde_sample_freq': 4, 'max_grad_norm': 0.5, 'vf_coef': 0.5, 'learning_rate': 3e-05, 'use_sde': True, 'policy_kwargs': {'log_std_init': -2.7, 'ortho_init': False, 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>, 'net_arch': {'pi': [256, 256], 'vf': [256, 256]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 17:54:49,579 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-01 17:54:49,579 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-01 17:54:49,579 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 17:54:49,580 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'batch_size': 64, 'gamma': 0.99, 'gae_lambda': 0.9, 'ent_coef': 0.0, 'sde_sample_freq': 4, 'max_grad_norm': 0.5, 'vf_coef': 0.5, 'learning_rate': 3e-05, 'use_sde': True, 'policy_kwargs': {'log_std_init': -2.7, 'ortho_init': False, 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>, 'net_arch': {'pi': [256, 256], 'vf': [256, 256]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 17:54:51,584 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/Pendulum-v1_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:45
2025-06-01 17:54:51,875 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:54:52,178 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 17:54:52,448 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:11,112 - INFO - ddpg_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:47
2025-06-01 18:46:11,113 - INFO - ddpg_algorithm.py:__init__ - : This RL environment uses a DDPG RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:48
2025-06-01 18:46:11,113 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 18:46:11,113 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 18:46:12,845 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/Pendulum-v1_ddpg\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:45
2025-06-01 18:46:13,306 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:14,163 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:14,994 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:15,835 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:19,351 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:20,254 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:21,143 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:22,015 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:22,909 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:23,834 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:24,746 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:25,626 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:26,529 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:27,446 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:28,361 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:42,964 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:43,933 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:44,950 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:45,978 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:46,987 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:47,989 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:48,992 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:50,007 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:51,010 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:52,000 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:53,004 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:54,021 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:55,105 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:56,087 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:57,098 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:58,109 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:59,107 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:46:59,913 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:00,432 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:01,419 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:02,425 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:03,416 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:04,408 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:05,408 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:06,452 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:07,469 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:08,468 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:09,475 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:10,480 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:11,488 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:12,523 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:13,542 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:14,535 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:15,549 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:16,562 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:17,562 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:18,574 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:19,559 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:20,568 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:21,572 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:22,578 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:23,591 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:24,599 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:25,596 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:26,644 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:27,686 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:28,715 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:29,739 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:30,747 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:31,817 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:32,850 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:33,864 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:34,867 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:35,910 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:36,921 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:37,953 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:38,984 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:39,982 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:41,008 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:42,003 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:43,061 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:44,067 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:45,093 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:46,106 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:47,195 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:48,234 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:49,312 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:47:50,359 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ddpg\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-01 18:54:24,176 - INFO - ddpg_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:47
2025-06-01 18:54:24,178 - INFO - ddpg_algorithm.py:__init__ - : This RL environment uses a DDPG RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:48
2025-06-01 18:54:24,180 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 18:54:24,182 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 18:57:10,231 - INFO - ddpg_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:47
2025-06-01 18:57:10,231 - INFO - ddpg_algorithm.py:__init__ - : This RL environment uses a DDPG RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:48
2025-06-01 18:57:10,247 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 18:57:10,247 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 19:01:49,949 - INFO - ddpg_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:47
2025-06-01 19:01:49,951 - INFO - ddpg_algorithm.py:__init__ - : This RL environment uses a DDPG RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:48
2025-06-01 19:01:49,953 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 19:01:49,955 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 19:08:59,395 - INFO - ddpg_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:47
2025-06-01 19:08:59,395 - INFO - ddpg_algorithm.py:__init__ - : This RL environment uses a DDPG RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:48
2025-06-01 19:08:59,411 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 19:08:59,411 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 19:09:52,511 - INFO - ddpg_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:47
2025-06-01 19:09:52,511 - INFO - ddpg_algorithm.py:__init__ - : This RL environment uses a DDPG RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:48
2025-06-01 19:09:52,511 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 19:09:52,512 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 19:11:13,435 - INFO - ddpg_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:47
2025-06-01 19:11:13,436 - INFO - ddpg_algorithm.py:__init__ - : This RL environment uses a DDPG RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:48
2025-06-01 19:11:13,440 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 19:11:13,442 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 19:13:22,453 - INFO - ddpg_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:47
2025-06-01 19:13:22,455 - INFO - ddpg_algorithm.py:__init__ - : This RL environment uses a DDPG RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:48
2025-06-01 19:13:22,457 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 19:13:22,459 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 19:44:58,203 - INFO - ddpg_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:47
2025-06-01 19:44:58,203 - INFO - ddpg_algorithm.py:__init__ - : This RL environment uses a DDPG RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:48
2025-06-01 19:44:58,203 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 19:44:58,204 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 19:46:26,796 - INFO - ddpg_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:47
2025-06-01 19:46:26,796 - INFO - ddpg_algorithm.py:__init__ - : This RL environment uses a DDPG RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:48
2025-06-01 19:46:26,796 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 19:46:26,797 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 19:48:25,693 - INFO - ddpg_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:47
2025-06-01 19:48:25,693 - INFO - ddpg_algorithm.py:__init__ - : This RL environment uses a DDPG RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:48
2025-06-01 19:48:25,694 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 19:48:25,694 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 19:52:02,569 - INFO - ddpg_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:47
2025-06-01 19:52:02,569 - INFO - ddpg_algorithm.py:__init__ - : This RL environment uses a DDPG RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:48
2025-06-01 19:52:02,569 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 19:52:02,570 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 19:54:34,292 - INFO - td3_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\td3_algorithm.py:49
2025-06-01 19:54:34,292 - INFO - td3_algorithm.py:__init__ - : This RL environment uses a TD3 RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\td3_algorithm.py:50
2025-06-01 19:54:34,293 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 19:54:34,293 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 19:55:28,008 - INFO - sac_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\sac_algorithm.py:47
2025-06-01 19:55:28,008 - INFO - sac_algorithm.py:__init__ - : This RL environment uses a SAC RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\sac_algorithm.py:48
2025-06-01 19:55:28,009 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 19:55:28,009 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9, 'learning_rate': 0.004843759072455456, 'batch_size': 1024, 'buffer_size': 10000, 'learning_starts': 1000, 'train_freq': 16, 'tau': 0.005, 'policy_kwargs': {'log_std_init': 0.2571311109643921, 'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
2025-06-01 19:56:17,097 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-01 19:56:17,097 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-01 19:56:17,097 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:113
2025-06-01 19:56:17,098 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'batch_size': 64, 'gamma': 0.99, 'gae_lambda': 0.9, 'ent_coef': 0.0, 'sde_sample_freq': 4, 'max_grad_norm': 0.5, 'vf_coef': 0.5, 'learning_rate': 3e-05, 'use_sde': True, 'policy_kwargs': {'log_std_init': -2.7, 'ortho_init': False, 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>, 'net_arch': {'pi': [256, 256], 'vf': [256, 256]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:114
