2025-06-05 21:01:50,545 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V0 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-05 21:01:50,545 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-05 21:01:50,545 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-05 21:01:50,552 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-05 21:01:52,313 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/CartPole-v0_dqn\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:45
2025-06-05 21:01:52,877 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-05 21:02:24,037 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V0 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-05 21:02:24,038 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-05 21:02:24,038 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-05 21:02:24,038 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-05 21:04:20,513 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V0 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-05 21:04:20,514 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-05 21:04:20,514 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-05 21:04:20,514 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-05 21:11:22,471 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V0 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-05 21:11:22,472 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-05 21:11:22,472 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-05 21:11:22,472 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-05 21:11:24,376 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/CartPole-v0_dqn\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:45
2025-06-05 21:11:24,924 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-05 21:11:51,571 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V0 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-05 21:11:51,572 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-05 21:11:51,572 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-05 21:11:51,572 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-05 21:13:27,483 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V0 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-05 21:13:27,484 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-05 21:13:27,484 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-05 21:13:27,484 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-05 21:13:29,330 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/CartPole-v0_dqn\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:45
2025-06-05 21:13:29,913 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-05 21:14:31,507 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V0 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-05 21:14:31,508 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-05 21:14:31,508 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-05 21:14:31,508 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-05 21:17:56,642 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V0 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-05 21:17:56,642 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-05 21:17:56,642 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-05 21:17:56,643 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-05 21:19:41,689 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V0 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-05 21:19:41,689 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-05 21:19:41,690 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-05 21:19:41,690 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-05 21:19:43,523 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/CartPole-v0_dqn\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:45
2025-06-05 21:19:44,110 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-05 21:19:44,789 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-05 21:19:45,450 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-05 21:19:46,127 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/CartPole-v0_dqn\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-05 21:20:17,225 - INFO - dqn_algorithm.py:__init__ - : Start of Reinforcement learning for environment: CARTPOLE-V0 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:47
2025-06-05 21:20:17,226 - INFO - dqn_algorithm.py:__init__ - : This RL environment uses a DQN RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\dqn_algorithm.py:48
2025-06-05 21:20:17,226 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-05 21:20:17,226 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-05 21:23:51,647 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 21:23:51,647 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 21:23:51,648 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-05 21:23:51,648 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'batch_size': 64, 'gamma': 0.99, 'gae_lambda': 0.9, 'ent_coef': 0.0, 'sde_sample_freq': 4, 'max_grad_norm': 0.5, 'vf_coef': 0.5, 'learning_rate': 3e-05, 'use_sde': True, 'policy_kwargs': {'log_std_init': -2.7, 'ortho_init': False, 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>, 'net_arch': {'pi': [256, 256], 'vf': [256, 256]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-05 21:24:32,574 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 21:24:32,575 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 21:24:32,575 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-05 21:24:32,575 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'batch_size': 64, 'gamma': 0.99, 'gae_lambda': 0.9, 'ent_coef': 0.0, 'sde_sample_freq': 4, 'max_grad_norm': 0.5, 'vf_coef': 0.5, 'learning_rate': 3e-05, 'use_sde': True, 'policy_kwargs': {'log_std_init': -2.7, 'ortho_init': False, 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>, 'net_arch': {'pi': [256, 256], 'vf': [256, 256]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-05 21:24:34,344 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/Pendulum-v1_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:45
2025-06-05 21:24:34,838 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-05 21:24:36,844 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-05 21:24:38,886 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-05 21:25:17,790 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 21:25:17,791 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 21:25:17,791 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-05 21:25:17,791 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'batch_size': 64, 'gamma': 0.99, 'gae_lambda': 0.9, 'ent_coef': 0.0, 'sde_sample_freq': 4, 'max_grad_norm': 0.5, 'vf_coef': 0.5, 'learning_rate': 3e-05, 'use_sde': True, 'policy_kwargs': {'log_std_init': -2.7, 'ortho_init': False, 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>, 'net_arch': {'pi': [256, 256], 'vf': [256, 256]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-05 21:27:05,854 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 21:27:05,854 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 21:27:05,855 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-05 21:27:05,855 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'batch_size': 64, 'gamma': 0.99, 'gae_lambda': 0.9, 'ent_coef': 0.0, 'sde_sample_freq': 4, 'max_grad_norm': 0.5, 'vf_coef': 0.5, 'learning_rate': 3e-05, 'use_sde': True, 'policy_kwargs': {'log_std_init': -2.7, 'ortho_init': False, 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>, 'net_arch': {'pi': [256, 256], 'vf': [256, 256]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-05 21:27:07,579 - INFO - save_on_base_reward_callback.py:_init_callback - : Saving trained RL model to ./logs/Pendulum-v1_ppo\best_model in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:45
2025-06-05 21:27:08,064 - INFO - save_on_base_reward_callback.py:_on_step - : Saving new best model to ./logs/Pendulum-v1_ppo\best_model.zip in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\save_on_base_reward_callback.py:66
2025-06-05 21:28:57,427 - INFO - ppo_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:48
2025-06-05 21:28:57,428 - INFO - ppo_algorithm.py:__init__ - : This RL environment uses a PPO RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ppo_algorithm.py:49
2025-06-05 21:28:57,428 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-05 21:28:57,429 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'batch_size': 64, 'gamma': 0.99, 'gae_lambda': 0.9, 'ent_coef': 0.0, 'sde_sample_freq': 4, 'max_grad_norm': 0.5, 'vf_coef': 0.5, 'learning_rate': 3e-05, 'use_sde': True, 'policy_kwargs': {'log_std_init': -2.7, 'ortho_init': False, 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>, 'net_arch': {'pi': [256, 256], 'vf': [256, 256]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-05 21:30:04,730 - INFO - sac_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\sac_algorithm.py:47
2025-06-05 21:30:04,732 - INFO - sac_algorithm.py:__init__ - : This RL environment uses a SAC RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\sac_algorithm.py:48
2025-06-05 21:30:04,732 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-05 21:30:04,732 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9, 'learning_rate': 0.004843759072455456, 'batch_size': 1024, 'buffer_size': 10000, 'learning_starts': 1000, 'train_freq': 16, 'tau': 0.005, 'policy_kwargs': {'log_std_init': 0.2571311109643921, 'net_arch': [64, 64]}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
2025-06-05 21:33:33,225 - INFO - ddpg_algorithm.py:__init__ - : Start of Reinforcement learning for environment: PENDULUM-V1 in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:47
2025-06-05 21:33:33,226 - INFO - ddpg_algorithm.py:__init__ - : This RL environment uses a DDPG RL algorithm agent in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\ddpg_algorithm.py:48
2025-06-05 21:33:33,226 - INFO - base_algorithms.py:hyper_parameters - : Training is using non-tuned hyperparameters... in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:116
2025-06-05 21:33:33,226 - INFO - base_algorithms.py:hyper_parameters - : Hyperparameters are:
{'gamma': 0.9999, 'learning_rate': 0.0005, 'batch_size': 128, 'policy_kwargs': {'net_arch': {'pi': [64, 64], 'qf': [64, 64]}}} in C:\Development\Python\AI\ReinforcementLearning\PyData2025-Presentation\demos\pendulum\src\main\rl_algorithms\train_evaluate_test\base_algorithms.py:117
