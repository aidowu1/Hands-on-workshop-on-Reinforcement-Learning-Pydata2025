{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPqmkQaww+yCgRUKre4YKA2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Demo Frozen Lake DQN Agent\n"," - Demos the Deep Q Network (DQN) off-policy RL agent for the Frozen Lake problem"],"metadata":{"id":"5NyTwwGG_mQQ"}},{"cell_type":"markdown","source":["#### Installs"],"metadata":{"id":"1yr034I0_z7g"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6wHutJWU_dMn","executionInfo":{"status":"ok","timestamp":1747061850310,"user_tz":-60,"elapsed":107658,"user":{"displayName":"adeidowu@hotmail.com","userId":"15313548625752705445"}},"outputId":"65652e18-df87-411d-ca81-d5fbad47fcb1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.1.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Collecting pyvirtualdisplay\n","  Downloading PyVirtualDisplay-3.0-py3-none-any.whl.metadata (943 bytes)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.13.2)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n","Installing collected packages: pyvirtualdisplay, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyvirtualdisplay-3.0\n"]}],"source":["! pip install gymnasium torch numpy matplotlib pyvirtualdisplay\n"]},{"cell_type":"code","source":[],"metadata":{"id":"jSSqQ6ia_6IR","executionInfo":{"status":"ok","timestamp":1747061850334,"user_tz":-60,"elapsed":20,"user":{"displayName":"adeidowu@hotmail.com","userId":"15313548625752705445"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["#### Imports"],"metadata":{"id":"TrcJhTi5TuqN"}},{"cell_type":"code","source":["import random\n","import numpy as np                                       # numerical ops\n","import gymnasium as gym                                  # Gymnasium environments\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from collections import deque\n","from pyvirtualdisplay import Display                     # headless display\n","import matplotlib.pyplot as plt\n","from matplotlib.animation import FuncAnimation\n","from IPython import display\n","from typing import List, Any\n"],"metadata":{"id":"RpcdOSkETzMi","executionInfo":{"status":"ok","timestamp":1747061858116,"user_tz":-60,"elapsed":7780,"user":{"displayName":"adeidowu@hotmail.com","userId":"15313548625752705445"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["#### Define global configs and variables"],"metadata":{"id":"x3Hiev2BT9WA"}},{"cell_type":"code","source":["# Rendering configs\n","DPI = 72\n","INTERVAL = 100 # ms"],"metadata":{"id":"JnOL8ZXYT0vC","executionInfo":{"status":"ok","timestamp":1747061858120,"user_tz":-60,"elapsed":10,"user":{"displayName":"adeidowu@hotmail.com","userId":"15313548625752705445"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["#### Utility class of helper functions"],"metadata":{"id":"ZIOHGPd5We6V"}},{"cell_type":"code","source":["class Helpers:\n","  \"\"\"\n","  Utility class of helper functions\n","  \"\"\"\n","  @staticmethod\n","  def animateEnvironment(images: List[Any]):\n","    \"\"\"\n","    Animates the environment\n","    :param images: Images\n","    \"\"\"\n","    plt.figure(\n","        figsize=(images[0].shape[1]/DPI,images[0].shape[0]/DPI),\n","        dpi=DPI\n","        )\n","    patch = plt.imshow(images[0])\n","    plt.axis=('off')\n","    animate = lambda i: patch.set_data(images[i])\n","    ani = FuncAnimation(\n","        plt.gcf(),\n","        animate,\n","        frames=len(images),\n","        interval=INTERVAL)\n","    display.display(display.HTML(ani.to_jshtml()))\n","    plt.close()\n","\n","  @staticmethod\n","  def toOneHotEncoding(state: int, state_size: int) -> np.ndarray:\n","    \"\"\"\n","    Converts a state to a one-hot vector\n","    :param state: State\n","    :param state_size: State size\n","    :return: One-hot vector\n","    \"\"\"\n","    vec = np.zeros(state_size, dtype=np.float32)\n","    vec[state] = 1.0\n","    return vec"],"metadata":{"id":"kwMmpG43UBLo","executionInfo":{"status":"ok","timestamp":1747061858135,"user_tz":-60,"elapsed":22,"user":{"displayName":"adeidowu@hotmail.com","userId":"15313548625752705445"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["#### Solution steps:\n"," - Step 1: Implement Deep Q Network\n"," - Step 2: Implement Replay buffer\n"," - Step 3: Implement the RL training loop\n"," - Step 4: Implement the RL evaluation (animation) policy"],"metadata":{"id":"HbbdxS2yW2yP"}},{"cell_type":"markdown","source":["##### Step 1: Implement Deep Q Network"],"metadata":{"id":"be9w4_RUYWqb"}},{"cell_type":"code","source":["class QNetwork(nn.Module):\n","    def __init__(self, state_size, action_size, hidden_size=64):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(state_size, hidden_size),\n","            nn.ReLU(),\n","            nn.Linear(hidden_size, hidden_size),\n","            nn.ReLU(),\n","            nn.Linear(hidden_size, action_size)\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n"],"metadata":{"id":"Wxc-vkt-YijD","executionInfo":{"status":"ok","timestamp":1747061858144,"user_tz":-60,"elapsed":10,"user":{"displayName":"adeidowu@hotmail.com","userId":"15313548625752705445"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["##### Step 2: Implement Replay buffer"],"metadata":{"id":"QfbUuCdkYoqb"}},{"cell_type":"code","source":["class ReplayBuffer:\n","    def __init__(self, capacity=10000):\n","        self.buffer = deque(maxlen=capacity)\n","\n","    def push(self, state, action, reward, next_state, done):\n","        self.buffer.append((state, action, reward, next_state, done))\n","\n","    def sample(self, batch_size):\n","        batch = random.sample(self.buffer, batch_size)\n","        s, a, r, s2, d = zip(*batch)\n","        return (np.vstack(s), np.array(a), np.array(r, dtype=np.float32),\n","                np.vstack(s2), np.array(d, dtype=np.uint8))\n","\n","    def __len__(self):\n","        return len(self.buffer)\n"],"metadata":{"id":"RSwdTbXiWmvt","executionInfo":{"status":"ok","timestamp":1747061858162,"user_tz":-60,"elapsed":17,"user":{"displayName":"adeidowu@hotmail.com","userId":"15313548625752705445"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["##### Step 3: RL training loop"],"metadata":{"id":"CrFKznO6YuqB"}},{"cell_type":"code","source":["class DqnAgentTrainingLoop:\n","  \"\"\"\n","  DQN agent training loop\n","  \"\"\"\n","  def __init__(\n","      self,\n","      env,\n","      n_episodes=2000,\n","      batch_size=64,\n","      gamma=0.99,\n","      lr=1e-3,\n","      target_update=50,\n","      epsilon = 1.0,\n","      eps_decay = 0.995,\n","      eps_min = 0.01\n","  ):\n","    \"\"\"\n","    Initializes the DQN agent training loop\n","    :param env: Environment\n","    :param n_episodes: Number of episodes\n","    :param batch_size: Batch size\n","    :param gamma: Discount factor\n","    :param lr: Learning rate\n","    :param target_update: Target update frequency\n","    :param epsilon: Epsilon\n","    :param eps_decay: Epsilon decay\n","    :param eps_min: Epsilon minimum\n","    \"\"\"\n","    self.env = env\n","    self.n_episodes = n_episodes\n","    self.batch_size = batch_size\n","    self.gamma = gamma\n","    self.lr = lr\n","    self.target_update = target_update\n","    self.epsilon = epsilon\n","    self.eps_decay = eps_decay\n","    self.eps_min = eps_min\n","\n","    self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    self.state_size = env.observation_space.n\n","    self.action_size = env.action_space.n\n","\n","    self.q_network = QNetwork(self.state_size, self.action_size).to(self.device)\n","    self.target_network = QNetwork(self.state_size, self.action_size).to(self.device)\n","    self.target_network.load_state_dict(self.q_network.state_dict())\n","    self.optimizer = optim.Adam(self.q_network.parameters(), lr=self.lr)\n","    self.replay_buffer = ReplayBuffer()\n","\n","  def _selectAction(\n","    self,\n","    q_net: QNetwork,\n","    state: Any,\n","    epsilon: float,\n","    n_actions: int) -> int:\n","    \"\"\"\n","    Selects an action\n","    :param q_net: Q network\n","    :param state: State\n","    :param epsilon: Epsilon\n","    :param n_actions: Number of actions\n","    :return: Action\n","    \"\"\"\n","    if random.random() < epsilon:\n","        return random.randrange(n_actions)\n","    with torch.no_grad():\n","        return q_net(torch.FloatTensor(state)).argmax().item()\n","\n","  def train(self):\n","    \"\"\"\n","    Trains the DQN agent\n","    \"\"\"\n","    all_rewards = []\n","\n","    for ep in range(1, self.n_episodes+1):\n","        state, _ = self.env.reset()\n","        state = Helpers.toOneHotEncoding(state, self.state_size)\n","        total_r = 0\n","\n","        done = False\n","        while not done:\n","            action = self._selectAction(\n","                self.q_network,\n","                state,\n","                self.epsilon,\n","                self.action_size)\n","            next_state, reward, done, _, _ = self.env.step(action)\n","            next_state = Helpers.toOneHotEncoding(next_state, self.state_size)\n","\n","            self.replay_buffer.push(state, action, reward, next_state, done)\n","            state = next_state\n","            total_r += reward\n","\n","            if len(self.replay_buffer) >= self.batch_size:\n","                s, a, r, s2, d = self.replay_buffer.sample(self.batch_size)\n","                s  = torch.FloatTensor(s)\n","                a  = torch.LongTensor(a)\n","                r  = torch.FloatTensor(r)\n","                s2 = torch.FloatTensor(s2)\n","                d  = torch.BoolTensor(d)\n","\n","                # Current Q\n","                q_vals = self.q_network(s).gather(1, a.unsqueeze(1)).squeeze(1)\n","                # Next Q from target network\n","                next_q = self.target_network(s2).max(1)[0]\n","                next_q[d] = 0.0  # zero for terminal states\n","                # DQN loss\n","                target = r + self.gamma * next_q\n","                loss = nn.functional.mse_loss(q_vals, target.detach())\n","\n","                self.optimizer.zero_grad()\n","                loss.backward()\n","                self.optimizer.step()\n","\n","        # Epsilon decay\n","        self.epsilon = max(self.eps_min, self.epsilon * self.eps_decay)\n","        all_rewards.append(total_r)\n","\n","        # Periodic target network update\n","        if ep % self.target_update == 0:\n","            self.target_network.load_state_dict(self.q_network.state_dict())\n","\n","        if ep % 200 == 0:\n","            print(f\"Episode {ep}, AvgReward {np.mean(all_rewards[-200:]):.3f}\")\n","\n","    return self.q_network, all_rewards\n","\n","  @property\n","  def q_net(self) -> QNetwork:\n","    \"\"\"\n","    Getter for the Q network\n","    :return: Q network\n","    \"\"\"\n","    return self.q_network"],"metadata":{"id":"z3TLZnN0ZS2f","executionInfo":{"status":"ok","timestamp":1747063040444,"user_tz":-60,"elapsed":46,"user":{"displayName":"adeidowu@hotmail.com","userId":"15313548625752705445"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["env = gym.make(\"FrozenLake-v1\", is_slippery=False, render_mode=\"rgb_array\")\n","agent = DqnAgentTrainingLoop(env)\n","q_net, rewards = agent.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yltq-K73CB5k","executionInfo":{"status":"ok","timestamp":1747064102051,"user_tz":-60,"elapsed":272188,"user":{"displayName":"adeidowu@hotmail.com","userId":"15313548625752705445"}},"outputId":"e8d33ed4-ea5f-4404-e2f4-e86df7c36ceb"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Episode 200, AvgReward 0.240\n","Episode 400, AvgReward 0.715\n","Episode 600, AvgReward 0.920\n","Episode 800, AvgReward 0.975\n","Episode 1000, AvgReward 0.995\n","Episode 1200, AvgReward 0.980\n","Episode 1400, AvgReward 0.985\n","Episode 1600, AvgReward 0.980\n","Episode 1800, AvgReward 0.785\n","Episode 2000, AvgReward 0.740\n"]}]},{"cell_type":"markdown","source":["##### Step 4: Implement the RL evaluation (animation) policy"],"metadata":{"id":"JLQuH8sagTtJ"}},{"cell_type":"code","source":["class EvaluateDQNAgent:\n","  \"\"\"\n","  Evaluate the DQN RL agent using animation of the simulation runs\n","  \"\"\"\n","  def __init__(self, agent, env, n_episodes=10):\n","    \"\"\"\n","    Constructor\n","    \"\"\"\n","    self.agent = agent\n","    self.env = env\n","    self.n_episodes = n_episodes\n","    self.display = Display(visible=0, size=(400, 400))\n","    self.display.start()\n","    self.trajectories = []\n","    self.images = []\n","\n","  def _evaluate(self):\n","    \"\"\"\n","    Evaluate the agent\n","    \"\"\"\n","    for ep in range(self.n_episodes):\n","      state, _ = self.env.reset()\n","      self.trajectories.append(state)\n","      one_hot = lambda s: np.eye(self.env.observation_space.n, dtype=np.float32)[s]\n","      done = False\n","\n","      #while not done:\n","      for _ in range(100):\n","        a = self.agent.q_net(torch.FloatTensor(one_hot(state))).argmax().item()\n","        state, _, done, _, _ = self.env.step(a)\n","        self.trajectories.append(state)\n","        self.images.append(self.env.render())\n","\n","        if done:\n","              break\n","\n","      self.env.close()\n","\n","  def run(self):\n","    \"\"\"\n","    Run the RL evaluation with animation\n","    \"\"\"\n","    self._evaluate()\n","    Helpers.animateEnvironment(self.images)"],"metadata":{"id":"u77pg7CdgWph","executionInfo":{"status":"ok","timestamp":1747064110716,"user_tz":-60,"elapsed":8,"user":{"displayName":"adeidowu@hotmail.com","userId":"15313548625752705445"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["evaluate = EvaluateDQNAgent(agent, env)\n","evaluate.run()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":354,"output_embedded_package_id":"1NccrQ3gv8_rh7iLl1f4c3YVOgJXXj0IY"},"id":"H-SKnLEejRSR","executionInfo":{"status":"ok","timestamp":1747064118305,"user_tz":-60,"elapsed":5672,"user":{"displayName":"adeidowu@hotmail.com","userId":"15313548625752705445"}},"outputId":"55351628-b458-458e-d18f-91281d76c715"},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"DJ2T1l-hFCDS"},"execution_count":null,"outputs":[]}]}